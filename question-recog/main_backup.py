#!/usr/bin/env python3
"""
é¢˜åº“è¯†åˆ«ç³»ç»Ÿ - ä¸»ç¨‹åº
ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸“æ³¨äºæ ¸å¿ƒåŠŸèƒ½
"""

import json
import argparse
from pathlib import Path
import pandas as pd
import re
from typing import List, Dict, Any
import sys

def enhanced_question_classifier(question: str, options: List[str], answer: str) -> tuple:
    """é¢˜ç›®åˆ†ç±»å™¨ï¼Œè¿”å›(ç±»å‹, ç½®ä¿¡åº¦)"""
    
    question = question.strip()
    answer = answer.strip()
    
    # 1. åˆ¤æ–­é¢˜è¯†åˆ«
    true_false_patterns = [
        r'(å¯¹|é”™|âˆš|Ã—|æ­£ç¡®|é”™è¯¯|æ˜¯|å¦)$',
        r'[ï¼ˆ(](å¯¹|é”™|âˆš|Ã—)[)ï¼‰]$',
        r'è¯´æ³•.*?(å¯¹|é”™|æ­£ç¡®|é”™è¯¯)',
        r'è¡¨è¿°.*?(å¯¹|é”™|æ­£ç¡®|é”™è¯¯)',
    ]
    
    for pattern in true_false_patterns:
        if re.search(pattern, question):
            return 'true_false', 0.9
    
    if len(options) == 2:
        option_text = ' '.join(options).lower()
        if any(keyword in option_text for keyword in ['å¯¹', 'é”™', 'âˆš', 'Ã—', 'true', 'false']):
            return 'true_false', 0.85
    
    # 2. å¡«ç©ºé¢˜è¯†åˆ«
    blank_patterns = [r'____+', r'ï¼ˆ\s*ï¼‰', r'\(\s*\)', r'ã€\s*ã€‘']
    for pattern in blank_patterns:
        if re.search(pattern, question):
            return 'fill_blank', 0.9
    
    # 3. é€‰æ‹©é¢˜è¯†åˆ«
    if len(options) >= 3:
        multi_keywords = ['å¤šé€‰', 'å¤šé¡¹', 'è‡³å°‘ä¸¤é¡¹', 'å“ªäº›', 'å“ªå‡ ä¸ª']
        if any(keyword in question for keyword in multi_keywords):
            return 'multiple_choice', 0.9
        elif len(answer) > 1 and all(c.isalpha() for c in answer):
            return 'multiple_choice', 0.8
        else:
            return 'single_choice', 0.85
    
    # 4. ç®€ç­”é¢˜è¯†åˆ«
    subjective_patterns = [
        r'^(ç®€è¿°|è¯´æ˜|è®ºè¿°|åˆ†æ|é˜è¿°|è§£é‡Š|æè¿°)',
        r'(å¦‚ä½•|ä¸ºä»€ä¹ˆ|ä»€ä¹ˆæ˜¯|æ€æ ·)',
        r'(è¯·|è¯•|è°ˆè°ˆ)',
    ]
    
    for pattern in subjective_patterns:
        if re.search(pattern, question):
            return 'subjective', 0.85
    
    if not options and len(answer) > 20:
        return 'subjective', 0.7
    
    return 'unknown', 0.0

def parse_excel_file(file_path: str) -> List[Dict[str, Any]]:
    """è§£æExcelæ–‡ä»¶"""
    questions = []
    
    try:
        df = pd.read_excel(file_path)
        current_question = None
        current_options = []
        question_buffer = []
        
        for idx, row in df.iterrows():
            row_text = " ".join(str(cell) for cell in row.values if pd.notna(cell) and str(cell).strip())
            
            if not row_text.strip():
                continue
            
            # é¢˜ç›®å¼€å§‹è¯†åˆ«
            question_start_patterns = [
                r'^\d+\s+[^0-9]',  # "1 è¿ç”¨ä¸­..."
                r'^\d+[.\ã€]\s*',   # "1. " æˆ– "1ã€"
                r'^ç¬¬\d+é¢˜',        # "ç¬¬1é¢˜"
                r'^\(\d+\)',        # "(1)"
            ]
            
            is_new_question = any(re.match(pattern, row_text.strip()) for pattern in question_start_patterns)
            
            if is_new_question:
                # å¤„ç†å‰ä¸€é¢˜
                if current_question and question_buffer:
                    question = process_question_buffer(question_buffer, current_options)
                    if question:
                        questions.append(question)
                
                # å¼€å§‹æ–°é¢˜
                current_question = row_text.strip()
                current_options = []
                question_buffer = [current_question]
            
            elif re.match(r'^[A-F][.\)]\s+', row_text.strip()):
                # é€‰é¡¹è¯†åˆ«
                current_options.append(row_text.strip())
                question_buffer.append(row_text.strip())
            else:
                # è¿½åŠ åˆ°é¢˜ç›®
                question_buffer.append(row_text.strip())
        
        # å¤„ç†æœ€åä¸€é¢˜
        if current_question and question_buffer:
            question = process_question_buffer(question_buffer, current_options)
            if question:
                questions.append(question)
    
    except Exception as e:
        print(f"âŒ Excelè§£æå¤±è´¥: {e}")
    
    return questions

def process_question_buffer(buffer: List[str], options: List[str]) -> Dict[str, Any]:
    """å¤„ç†é¢˜ç›®ç¼“å†²åŒº"""
    full_text = " ".join(buffer)
    
    # æå–ç­”æ¡ˆ
    answer_patterns = [
        r'ç­”æ¡ˆ[:ï¼š]\s*([^\s\n]+)',
        r'æ­£ç¡®ç­”æ¡ˆ[:ï¼š]\s*([^\s\n]+)',
        r'å‚è€ƒç­”æ¡ˆ[:ï¼š]\s*([^\s\n]+)',
    ]
    
    answer = ""
    for pattern in answer_patterns:
        match = re.search(pattern, full_text)
        if match:
            answer = match.group(1)
            break
    
    # æ¸…ç†é¢˜ç›®
    clean_question = full_text
    clean_question = re.sub(r'\s*ç­”æ¡ˆ[:ï¼š].*$', '', clean_question)
    clean_question = re.sub(r'\s*(å¡«ç©ºé¢˜|é€‰æ‹©é¢˜|åˆ¤æ–­é¢˜|ç®€ç­”é¢˜|å¤šé€‰é¢˜).*$', '', clean_question)
    clean_question = re.sub(r'^\d+[.\ã€]?\s*', '', clean_question)
    
    # åˆ†ç±»
    question_type, confidence = enhanced_question_classifier(clean_question, options, answer)
    
    if clean_question.strip():
        return {
            'question': clean_question.strip(),
            'options': options.copy(),
            'answer': answer.strip(),
            'type': question_type,
            'confidence': confidence
        }
    
    return None

def process_files(input_dir: str, output_file: str = "enhanced_results.json"):
    """å¤„ç†é¢˜åº“æ–‡ä»¶"""
    print("ğŸš€ é¢˜åº“è¯†åˆ«ç³»ç»Ÿ")
    print("=" * 50)
    
    # æŸ¥æ‰¾é¢˜åº“æ–‡ä»¶
    tiku_dir = Path(input_dir)
    if not tiku_dir.exists():
        print(f"âŒ é¢˜åº“ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return
    
    excel_files = list(tiku_dir.glob("*.xlsx"))
    if not excel_files:
        print("âŒ æœªæ‰¾åˆ°Excelæ–‡ä»¶")
        return
    
    all_results = []
    
    for excel_file in excel_files:
        print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {excel_file.name}")
        
        questions = parse_excel_file(str(excel_file))
        
        for i, q in enumerate(questions):
            result = {
                "source_id": f"file://{excel_file.name}#q{i+1}",
                "question": q['question'],
                "options": q['options'],
                "answer_raw": q['answer'],
                "predicted_type": q['type'],
                "confidence": q['confidence'],
                "method": "enhanced_rule_based"
            }
            all_results.append(result)
        
        print(f"  ğŸ“Š è¯†åˆ«åˆ° {len(questions)} ä¸ªé¢˜ç›®")
    
    # ç»Ÿè®¡ç»“æœ
    print_statistics(all_results)
    
    # ä¿å­˜ç»“æœ
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {output_file}")
    
    # æ˜¾ç¤ºç¤ºä¾‹
    show_examples(all_results)
    
    return len(all_results)

def print_statistics(results: List[Dict]):
    """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
    if not results:
        return
    
    # é¢˜å‹ç»Ÿè®¡
    type_counts = {}
    confidence_levels = {"high": 0, "medium": 0, "low": 0, "unknown": 0}
    
    for result in results:
        q_type = result["predicted_type"]
        confidence = result["confidence"]
        
        type_counts[q_type] = type_counts.get(q_type, 0) + 1
        
        if confidence >= 0.8:
            confidence_levels["high"] += 1
        elif confidence >= 0.6:
            confidence_levels["medium"] += 1
        elif confidence >= 0.4:
            confidence_levels["low"] += 1
        else:
            confidence_levels["unknown"] += 1
    
    print(f"\nğŸ“Š å¤„ç†æ€»ç»“")
    print(f"é¢˜ç›®æ€»æ•°: {len(results)}")
    
    print(f"\nğŸ“ˆ é¢˜å‹åˆ†å¸ƒ:")
    for q_type, count in sorted(type_counts.items()):
        percentage = count / len(results) * 100
        print(f"  {q_type:<15}: {count:>4} é¢˜ ({percentage:>5.1f}%)")
    
    print(f"\nğŸ¯ ç½®ä¿¡åº¦åˆ†å¸ƒ:")
    for level, count in confidence_levels.items():
        percentage = count / len(results) * 100
        print(f"  {level:<10}: {count:>4} é¢˜ ({percentage:>5.1f}%)")

def show_examples(results: List[Dict], max_examples: int = 3):
    """æ˜¾ç¤ºé¢˜ç›®ç¤ºä¾‹"""
    print(f"\nğŸ“ é¢˜ç›®ç¤ºä¾‹:")
    
    shown_types = set()
    example_count = 0
    
    for result in results:
        if result['predicted_type'] not in shown_types and example_count < max_examples:
            shown_types.add(result['predicted_type'])
            example_count += 1
            
            print(f"  ã€{result['predicted_type']}ã€‘(ç½®ä¿¡åº¦: {result['confidence']:.1f})")
            print(f"    é¢˜å¹²: {result['question'][:80]}...")
            if result['options']:
                print(f"    é€‰é¡¹: {', '.join(result['options'][:2])}...")
            print(f"    ç­”æ¡ˆ: {result['answer_raw'][:30]}...")
            print()

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='é¢˜åº“è¯†åˆ«ç³»ç»Ÿ')
    parser.add_argument('--input', '-i', default='../é¢˜åº“', help='é¢˜åº“ç›®å½•è·¯å¾„')
    parser.add_argument('--output', '-o', default='enhanced_results.json', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--version', '-v', action='version', version='é¢˜åº“è¯†åˆ«ç³»ç»Ÿ v2.0')
    
    args = parser.parse_args()
    
    try:
        total = process_files(args.input, args.output)
        
        if total > 0:
            print("\nğŸ‰ å¤„ç†å®Œæˆï¼")
            print(f"ğŸ“Š æˆåŠŸè¯†åˆ« {total} ä¸ªé¢˜ç›®")
            print(f"ğŸ“‹ è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹: {args.output}")
        else:
            print("\nâŒ æœªå¤„ç†ä»»ä½•é¢˜ç›®ï¼Œè¯·æ£€æŸ¥è¾“å…¥ç›®å½•å’Œæ–‡ä»¶æ ¼å¼")
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
