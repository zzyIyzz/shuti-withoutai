#!/usr/bin/env python
"""
ç”Ÿäº§ç¯å¢ƒå¿«é€Ÿä½¿ç”¨è„šæœ¬
æ¼”ç¤ºå¦‚ä½•åœ¨å®é™…ç¯å¢ƒä¸­ä½¿ç”¨é¢˜å‹è¯†åˆ«ç³»ç»Ÿ
"""

import sys
from pathlib import Path
import json

# æ·»åŠ srcåˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.io.readers import DocumentReader
from src.pipeline import QuestionRecognitionPipeline


def process_real_files():
    """å¤„ç†çœŸå®çš„é¢˜åº“æ–‡ä»¶"""
    print("ğŸš€ ç”Ÿäº§ç¯å¢ƒé¢˜åº“è¯†åˆ«ç³»ç»Ÿ")
    print("=" * 40)
    
    # é…ç½®ï¼ˆç”Ÿäº§ç¯å¢ƒä¼˜åŒ–ï¼‰
    config = {
        "paths": {
            "model_path": "src/model/xgb_model.json",
            "calibration_path": "calibration/calibration.json"
        },
        "thresholds": {
            "min_confidence": 0.4,
            "accept": {
                "single_choice": 0.75,    # ç¨å¾®é™ä½é˜ˆå€¼æé«˜å¬å›ç‡
                "multiple_choice": 0.75,
                "true_false": 0.70,
                "fill_blank": 0.65,
                "subjective": 0.60,
            },
            "review": {
                "single_choice": 0.50,
                "multiple_choice": 0.50,
                "true_false": 0.45,
                "fill_blank": 0.40,
                "subjective": 0.35,
            }
        }
    }
    
    # åˆ›å»ºç³»ç»Ÿç»„ä»¶
    pipeline = QuestionRecognitionPipeline(config)
    reader = DocumentReader()
    
    # æ£€æŸ¥é¢˜åº“ç›®å½•
    tiku_dir = Path("../é¢˜åº“")
    if not tiku_dir.exists():
        # å°è¯•ç»å¯¹è·¯å¾„
        tiku_dir = Path(__file__).parent.parent / "é¢˜åº“"
        if not tiku_dir.exists():
            print("âŒ é¢˜åº“ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿æœ‰é¢˜åº“æ–‡ä»¶")
            print(f"   æŸ¥æ‰¾è·¯å¾„1: {Path('../é¢˜åº“').absolute()}")
            print(f"   æŸ¥æ‰¾è·¯å¾„2: {tiku_dir.absolute()}")
            return
    
    # æŸ¥æ‰¾é¢˜åº“æ–‡ä»¶
    supported_files = []
    for pattern in ["*.xlsx", "*.docx", "*.pdf"]:
        supported_files.extend(tiku_dir.glob(pattern))
    
    if not supported_files:
        print("âŒ æœªæ‰¾åˆ°æ”¯æŒçš„é¢˜åº“æ–‡ä»¶ (.xlsx, .docx, .pdf)")
        return
    
    print(f"ğŸ“š å‘ç° {len(supported_files)} ä¸ªé¢˜åº“æ–‡ä»¶")
    
    all_results = []
    stats_summary = {
        "total_files": 0,
        "total_questions": 0,
        "type_distribution": {},
        "confidence_levels": {"high": 0, "medium": 0, "low": 0, "review": 0}
    }
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for file_path in supported_files[:3]:  # å…ˆå¤„ç†å‰3ä¸ªæ–‡ä»¶ä½œä¸ºç¤ºä¾‹
        print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶: {file_path.name}")
        
        try:
            # è¯»å–æ–‡æ¡£
            document = reader.read_document(str(file_path))
            
            # è¯†åˆ«é¢˜å‹
            results = pipeline.process_document(document)
            all_results.extend(results)
            
            # ç»Ÿè®¡ä¿¡æ¯
            stats_summary["total_files"] += 1
            stats_summary["total_questions"] += len(results)
            
            print(f"  ğŸ“Š è¯†åˆ«åˆ° {len(results)} ä¸ªé¢˜ç›®")
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªç»“æœ
            for i, result in enumerate(results[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                qtype = result.final_result.type.value
                confidence = result.final_result.confidence
                
                # æ›´æ–°ç»Ÿè®¡
                if qtype not in stats_summary["type_distribution"]:
                    stats_summary["type_distribution"][qtype] = 0
                stats_summary["type_distribution"][qtype] += 1
                
                # ç½®ä¿¡åº¦åˆ†çº§
                if confidence >= 0.8:
                    stats_summary["confidence_levels"]["high"] += 1
                elif confidence >= 0.6:
                    stats_summary["confidence_levels"]["medium"] += 1
                elif confidence >= 0.4:
                    stats_summary["confidence_levels"]["low"] += 1
                else:
                    stats_summary["confidence_levels"]["review"] += 1
                
                status = "âœ…" if confidence >= 0.6 else "âš ï¸" if confidence >= 0.4 else "âŒ"
                review_flag = " [éœ€å¤æ ¸]" if result.final_result.needs_review else ""
                
                print(f"    {status} é¢˜ç›®{i+1}: {qtype} (ç½®ä¿¡åº¦: {confidence:.3f}){review_flag}")
                print(f"       é¢˜å¹²: {result.question.question[:50]}...")
                
                if result.rule_decision:
                    print(f"       è§„åˆ™: {result.rule_decision.rule_name}")
                
        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
    
    # è¾“å‡ºæ€»ä½“ç»Ÿè®¡
    print(f"\nğŸ“Š å¤„ç†æ€»ç»“")
    print(f"æ–‡ä»¶æ•°é‡: {stats_summary['total_files']}")
    print(f"é¢˜ç›®æ€»æ•°: {stats_summary['total_questions']}")
    
    print(f"\nğŸ“ˆ é¢˜å‹åˆ†å¸ƒ:")
    for qtype, count in stats_summary["type_distribution"].items():
        percentage = (count / stats_summary['total_questions']) * 100
        print(f"  {qtype:15}: {count:3} é¢˜ ({percentage:5.1f}%)")
    
    print(f"\nğŸ¯ ç½®ä¿¡åº¦åˆ†å¸ƒ:")
    total_q = stats_summary['total_questions']
    if total_q > 0:
        print(f"  é«˜ç½®ä¿¡åº¦ (â‰¥0.8): {stats_summary['confidence_levels']['high']:3} é¢˜ ({stats_summary['confidence_levels']['high']/total_q*100:5.1f}%)")
        print(f"  ä¸­ç½®ä¿¡åº¦ (0.6-0.8): {stats_summary['confidence_levels']['medium']:3} é¢˜ ({stats_summary['confidence_levels']['medium']/total_q*100:5.1f}%)")
        print(f"  ä½ç½®ä¿¡åº¦ (0.4-0.6): {stats_summary['confidence_levels']['low']:3} é¢˜ ({stats_summary['confidence_levels']['low']/total_q*100:5.1f}%)")
        print(f"  éœ€è¦å¤æ ¸ (<0.4): {stats_summary['confidence_levels']['review']:3} é¢˜ ({stats_summary['confidence_levels']['review']/total_q*100:5.1f}%)")
    
    # ä¿å­˜ç»“æœ
    output_file = Path("production_results.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            "summary": stats_summary,
            "results": [result.model_dump() for result in all_results]
        }, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜è‡³: {output_file}")
    
    # ç»™å‡ºå»ºè®®
    print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    if stats_summary['confidence_levels']['review'] > 0:
        print(f"  â€¢ æœ‰ {stats_summary['confidence_levels']['review']} ä¸ªé¢˜ç›®éœ€è¦äººå·¥å¤æ ¸")
    
    high_conf_rate = stats_summary['confidence_levels']['high'] / total_q if total_q > 0 else 0
    if high_conf_rate < 0.6:
        print(f"  â€¢ é«˜ç½®ä¿¡åº¦æ¯”ä¾‹è¾ƒä½ ({high_conf_rate:.1%})ï¼Œå»ºè®®è®­ç»ƒXGBoostæ¨¡å‹")
    
    unknown_count = stats_summary["type_distribution"].get("unknown", 0)
    if unknown_count > 0:
        print(f"  â€¢ æœ‰ {unknown_count} ä¸ªæœªçŸ¥é¢˜å‹ï¼Œå»ºè®®ä¼˜åŒ–è§„åˆ™æˆ–è®­ç»ƒæ¨¡å‹")
    
    print(f"\nğŸ‰ ç”Ÿäº§ç¯å¢ƒæµ‹è¯•å®Œæˆï¼ç³»ç»Ÿå¯ä»¥æŠ•å…¥ä½¿ç”¨ã€‚")


if __name__ == "__main__":
    process_real_files()
