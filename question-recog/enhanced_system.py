#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆé¢˜ç›®åˆ†ç±»å™¨ - æ”¯æŒæ›´å¤šé¢˜å‹è¯†åˆ«
"""

import json
from pathlib import Path
import pandas as pd
import re
from typing import List, Dict, Any

def enhanced_question_classifier(question: str, options: List[str], answer: str) -> tuple:
    """å¢å¼ºç‰ˆé¢˜ç›®åˆ†ç±»å™¨ï¼Œè¿”å›(ç±»å‹, ç½®ä¿¡åº¦)"""
    
    # æ¸…ç†è¾“å…¥
    question = question.strip()
    answer = answer.strip()
    
    # 1. åˆ¤æ–­é¢˜è¯†åˆ«ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
    true_false_patterns = [
        r'(å¯¹|é”™|âˆš|Ã—|æ­£ç¡®|é”™è¯¯|æ˜¯|å¦)$',
        r'[ï¼ˆ(](å¯¹|é”™|âˆš|Ã—)[)ï¼‰]$',
        r'è¯´æ³•.*?(å¯¹|é”™|æ­£ç¡®|é”™è¯¯)',
        r'è¡¨è¿°.*?(å¯¹|é”™|æ­£ç¡®|é”™è¯¯)',
        r'åˆ¤æ–­.*?(å¯¹|é”™)',
    ]
    
    for pattern in true_false_patterns:
        if re.search(pattern, question):
            return 'true_false', 0.9
    
    if len(options) == 2:
        option_text = ' '.join(options).lower()
        if any(keyword in option_text for keyword in ['å¯¹', 'é”™', 'âˆš', 'Ã—', 'true', 'false', 'a. å¯¹', 'b. é”™']):
            return 'true_false', 0.85
    
    # 2. å¡«ç©ºé¢˜è¯†åˆ«
    blank_patterns = [
        r'____+',
        r'ï¼ˆ\s*ï¼‰',
        r'\(\s*\)',
        r'ã€\s*ã€‘',
        r'ç­‰äº\s*$',
        r'çº¦ä¸º\s*$',
        r'æ˜¯\s*$',
        r'ä¸º\s*$',
    ]
    
    for pattern in blank_patterns:
        if re.search(pattern, question):
            return 'fill_blank', 0.9
    
    # 3. é€‰æ‹©é¢˜è¯†åˆ«
    if len(options) >= 3:
        # å¤šé€‰é¢˜å…³é”®è¯
        multi_keywords = ['å¤šé€‰', 'å¤šé¡¹', 'è‡³å°‘ä¸¤é¡¹', 'ä¸¤ä¸ªä»¥ä¸Š', 'ä¸æ­¢ä¸€ä¸ª', 'å“ªäº›', 'å“ªå‡ ä¸ª', 'åŒ…æ‹¬']
        if any(keyword in question for keyword in multi_keywords):
            return 'multiple_choice', 0.9
        
        # æ ¹æ®ç­”æ¡ˆé•¿åº¦åˆ¤æ–­
        if len(answer) > 1 and all(c.isalpha() for c in answer):
            return 'multiple_choice', 0.8
        else:
            return 'single_choice', 0.85
    
    # 4. ç®€ç­”é¢˜è¯†åˆ«
    subjective_patterns = [
        r'^(ç®€è¿°|è¯´æ˜|è®ºè¿°|åˆ†æ|é˜è¿°|è§£é‡Š|æè¿°)',
        r'(å¦‚ä½•|ä¸ºä»€ä¹ˆ|ä»€ä¹ˆæ˜¯|æ€æ ·)',
        r'(è¯·|è¯•|è°ˆè°ˆ)',
        r'(åŸºæœ¬è¦æ±‚|å·¥ä½œåŸç†|ä¸»è¦ç‰¹ç‚¹|æ³¨æ„äº‹é¡¹)',
        r'(æ“ä½œæ­¥éª¤|æ£€ä¿®æ–¹æ³•|æ•…éšœå¤„ç†|å®‰å…¨è¦æ±‚)',
    ]
    
    for pattern in subjective_patterns:
        if re.search(pattern, question):
            return 'subjective', 0.85
    
    # å¦‚æœæ²¡æœ‰é€‰é¡¹ä¸”ç­”æ¡ˆå¾ˆé•¿ï¼Œä¹Ÿè®¤ä¸ºæ˜¯ç®€ç­”é¢˜
    if not options and len(answer) > 20:
        return 'subjective', 0.7
    
    # 5. æ ¹æ®é¢˜ç›®å†…å®¹è¿›ä¸€æ­¥åˆ¤æ–­
    question_lower = question.lower()
    
    # ç”µåŠ›ä¸“ä¸šåˆ¤æ–­é¢˜ç‰¹å¾
    power_tf_keywords = ['ç¬¦åˆè§„ç¨‹', 'è¿åè§„å®š', 'å®‰å…¨è§„èŒƒ', 'æŠ€æœ¯æ ‡å‡†', 'å…è®¸', 'ç¦æ­¢', 'å¿…é¡»', 'åº”å½“', 'ä¸å¾—']
    if any(keyword in question for keyword in power_tf_keywords):
        return 'true_false', 0.75
    
    # ç”µåŠ›ä¸“ä¸šå¡«ç©ºé¢˜ç‰¹å¾  
    power_blank_keywords = ['é¢å®š', 'å®¹é‡', 'ç”µå‹ç­‰çº§', 'é¢‘ç‡', 'åŠŸç‡', 'ç”µæµ', 'ç”µå‹', 'é˜»æŠ—', 'å‚æ•°', 'æ•°å€¼', 'èŒƒå›´', 'é™å€¼']
    if any(keyword in question for keyword in power_blank_keywords):
        return 'fill_blank', 0.7
    
    return 'unknown', 0.0

def enhanced_parse_excel(file_path: str) -> List[Dict[str, Any]]:
    """å¢å¼ºç‰ˆExcelè§£æ"""
    questions = []
    
    try:
        df = pd.read_excel(file_path)
        
        current_question = None
        current_options = []
        question_buffer = []
        
        for idx, row in df.iterrows():
            row_text = " ".join(str(cell) for cell in row.values if pd.notna(cell) and str(cell).strip())
            
            if not row_text.strip():
                continue
            
            # é¢˜ç›®ç¼–å·è¯†åˆ«ï¼ˆæ›´å‡†ç¡®ï¼‰
            question_start_patterns = [
                r'^\d+\s+[^0-9]',  # "1 è¿ç”¨ä¸­..."
                r'^\d+[.\ã€]\s*',   # "1. " æˆ– "1ã€"
                r'^ç¬¬\d+é¢˜',        # "ç¬¬1é¢˜"
                r'^\(\d+\)',        # "(1)"
            ]
            
            is_new_question = any(re.match(pattern, row_text.strip()) for pattern in question_start_patterns)
            
            if is_new_question:
                # å¤„ç†å‰ä¸€ä¸ªé¢˜ç›®
                if current_question and question_buffer:
                    full_question = " ".join(question_buffer)
                    
                    # æå–ç­”æ¡ˆ
                    answer_patterns = [
                        r'ç­”æ¡ˆ[:ï¼š]\s*([^\s\n]+)',
                        r'æ­£ç¡®ç­”æ¡ˆ[:ï¼š]\s*([^\s\n]+)',
                        r'å‚è€ƒç­”æ¡ˆ[:ï¼š]\s*([^\s\n]+)',
                    ]
                    
                    answer = ""
                    for pattern in answer_patterns:
                        match = re.search(pattern, full_question)
                        if match:
                            answer = match.group(1)
                            break
                    
                    # æ¸…ç†é¢˜ç›®ï¼ˆç§»é™¤ç­”æ¡ˆã€é¢˜å‹æ ‡è®°ç­‰ï¼‰
                    clean_question = full_question
                    clean_question = re.sub(r'\s*ç­”æ¡ˆ[:ï¼š].*$', '', clean_question)
                    clean_question = re.sub(r'\s*(å¡«ç©ºé¢˜|é€‰æ‹©é¢˜|åˆ¤æ–­é¢˜|ç®€ç­”é¢˜|å¤šé€‰é¢˜).*$', '', clean_question)
                    clean_question = re.sub(r'^\d+[.\ã€]?\s*', '', clean_question)  # ç§»é™¤é¢˜å·
                    
                    # åˆ†ç±»
                    question_type, confidence = enhanced_question_classifier(clean_question, current_options, answer)
                    
                    if clean_question.strip():  # ç¡®ä¿é¢˜ç›®ä¸ä¸ºç©º
                        questions.append({
                            'question': clean_question.strip(),
                            'options': current_options.copy(),
                            'answer': answer.strip(),
                            'type': question_type,
                            'confidence': confidence
                        })
                
                # å¼€å§‹æ–°é¢˜ç›®
                current_question = row_text.strip()
                current_options = []
                question_buffer = [current_question]
            
            # é€‰é¡¹è¯†åˆ«
            elif re.match(r'^[A-F][.\)]\s+', row_text.strip()):
                current_options.append(row_text.strip())
                question_buffer.append(row_text.strip())
            
            # å¦åˆ™è¿½åŠ åˆ°é¢˜ç›®ç¼“å†²åŒº
            else:
                question_buffer.append(row_text.strip())
        
        # å¤„ç†æœ€åä¸€ä¸ªé¢˜ç›®
        if current_question and question_buffer:
            full_question = " ".join(question_buffer)
            
            answer_patterns = [
                r'ç­”æ¡ˆ[:ï¼š]\s*([^\s\n]+)',
                r'æ­£ç¡®ç­”æ¡ˆ[:ï¼š]\s*([^\s\n]+)',
                r'å‚è€ƒç­”æ¡ˆ[:ï¼š]\s*([^\s\n]+)',
            ]
            
            answer = ""
            for pattern in answer_patterns:
                match = re.search(pattern, full_question)
                if match:
                    answer = match.group(1)
                    break
            
            clean_question = full_question
            clean_question = re.sub(r'\s*ç­”æ¡ˆ[:ï¼š].*$', '', clean_question)
            clean_question = re.sub(r'\s*(å¡«ç©ºé¢˜|é€‰æ‹©é¢˜|åˆ¤æ–­é¢˜|ç®€ç­”é¢˜|å¤šé€‰é¢˜).*$', '', clean_question)
            clean_question = re.sub(r'^\d+[.\ã€]?\s*', '', clean_question)
            
            question_type, confidence = enhanced_question_classifier(clean_question, current_options, answer)
            
            if clean_question.strip():
                questions.append({
                    'question': clean_question.strip(),
                    'options': current_options.copy(),
                    'answer': answer.strip(),
                    'type': question_type,
                    'confidence': confidence
                })
    
    except Exception as e:
        print(f"Excelè§£æå¤±è´¥: {e}")
    
    return questions

def test_enhanced_system():
    """æµ‹è¯•å¢å¼ºç‰ˆç³»ç»Ÿ"""
    print("ğŸš€ æµ‹è¯•å¢å¼ºç‰ˆé¢˜ç›®è¯†åˆ«ç³»ç»Ÿ")
    print("=" * 50)
    
    # æŸ¥æ‰¾é¢˜åº“æ–‡ä»¶
    tiku_dir = Path("../é¢˜åº“")
    if not tiku_dir.exists():
        tiku_dir = Path(__file__).parent.parent / "é¢˜åº“"
        if not tiku_dir.exists():
            print("âŒ é¢˜åº“ç›®å½•ä¸å­˜åœ¨")
            return
    
    excel_files = list(tiku_dir.glob("*.xlsx"))
    if not excel_files:
        print("âŒ æœªæ‰¾åˆ°Excelæ–‡ä»¶")
        return
    
    all_results = []
    
    for excel_file in excel_files:
        print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {excel_file.name}")
        
        questions = enhanced_parse_excel(str(excel_file))
        
        for i, q in enumerate(questions):
            result = {
                "source_id": f"file://{excel_file.name}#q{i+1}",
                "question": q['question'],
                "options": q['options'],
                "answer_raw": q['answer'],
                "predicted_type": q['type'],
                "confidence": q['confidence'],
                "method": "enhanced_rule_based"
            }
            all_results.append(result)
        
        print(f"  ğŸ“Š è¯†åˆ«åˆ° {len(questions)} ä¸ªé¢˜ç›®")
    
    # ç»Ÿè®¡ç»“æœ
    type_counts = {}
    confidence_levels = {"high": 0, "medium": 0, "low": 0, "unknown": 0}
    
    for result in all_results:
        q_type = result["predicted_type"]
        confidence = result["confidence"]
        
        type_counts[q_type] = type_counts.get(q_type, 0) + 1
        
        if confidence >= 0.8:
            confidence_levels["high"] += 1
        elif confidence >= 0.6:
            confidence_levels["medium"] += 1
        elif confidence >= 0.4:
            confidence_levels["low"] += 1
        else:
            confidence_levels["unknown"] += 1
    
    print(f"\nğŸ“Š å¤„ç†æ€»ç»“")
    print(f"é¢˜ç›®æ€»æ•°: {len(all_results)}")
    
    print(f"\nğŸ“ˆ é¢˜å‹åˆ†å¸ƒ:")
    for q_type, count in sorted(type_counts.items()):
        percentage = count / len(all_results) * 100 if all_results else 0
        print(f"  {q_type:<15}: {count:>4} é¢˜ ({percentage:>5.1f}%)")
    
    print(f"\nğŸ¯ ç½®ä¿¡åº¦åˆ†å¸ƒ:")
    for level, count in confidence_levels.items():
        percentage = count / len(all_results) * 100 if all_results else 0
        print(f"  {level:<10}: {count:>4} é¢˜ ({percentage:>5.1f}%)")
    
    # ä¿å­˜ç»“æœ
    output_file = "enhanced_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {output_file}")
    
    # æ˜¾ç¤ºå„ç±»å‹é¢˜ç›®ç¤ºä¾‹
    print(f"\nğŸ“ å„é¢˜å‹ç¤ºä¾‹:")
    shown_types = set()
    for result in all_results:
        if result['predicted_type'] not in shown_types and len(shown_types) < 5:
            shown_types.add(result['predicted_type'])
            print(f"  ã€{result['predicted_type']}ã€‘(ç½®ä¿¡åº¦: {result['confidence']:.1f})")
            print(f"    é¢˜å¹²: {result['question'][:100]}...")
            if result['options']:
                print(f"    é€‰é¡¹: {', '.join(result['options'][:2])}...")
            print(f"    ç­”æ¡ˆ: {result['answer_raw'][:50]}...")
            print()
    
    return len(all_results), type_counts, confidence_levels

if __name__ == "__main__":
    total, types, confidence = test_enhanced_system()
    
    if total > 0:
        print("ğŸ‰ å¢å¼ºç‰ˆç³»ç»Ÿè¿è¡ŒæˆåŠŸï¼")
        print(f"ğŸ“Š æˆåŠŸè¯†åˆ« {total} ä¸ªé¢˜ç›®")
        print(f"ğŸ“ˆ è¯†åˆ«äº† {len(types)} ç§é¢˜å‹")
        high_conf_ratio = confidence['high'] / total * 100 if total > 0 else 0
        print(f"ğŸ¯ é«˜ç½®ä¿¡åº¦é¢˜ç›®å æ¯”: {high_conf_ratio:.1f}%")
    else:
        print("âŒ ä»æœ‰é—®é¢˜éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
