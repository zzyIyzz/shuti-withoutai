#!/usr/bin/env python3
"""
å¿«é€Ÿè®­ç»ƒè„šæœ¬ - ç›´æ¥ä½¿ç”¨æ‰©å±•æ•°æ®
"""

import json
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, f1_score
from sklearn.preprocessing import LabelEncoder
import xgboost as xgb
from collections import Counter
import joblib
import random

def quick_train():
    """å¿«é€Ÿè®­ç»ƒæ¨¡å‹"""
    print("ğŸš€ å¿«é€Ÿè®­ç»ƒæ”¹è¿›æ¨¡å‹")
    print("=" * 40)
    
    # åŠ è½½æ‰©å±•æ•°æ®
    expanded_file = Path("data/labels/expanded_labels.jsonl")
    if not expanded_file.exists():
        print("âŒ æ‰©å±•æ•°æ®ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ expand_data.py")
        return
    
    # è¯»å–æ ‡æ³¨æ•°æ®
    samples = []
    with open(expanded_file, 'r', encoding='utf-8') as f:
        for line in f:
            sample = json.loads(line.strip())
            samples.append(sample)
    
    print(f"ğŸ“Š åŠ è½½äº† {len(samples)} ä¸ªæ ‡æ³¨æ ·æœ¬")
    
    # ç”Ÿæˆæ¨¡æ‹Ÿç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
    X = []
    y = []
    
    for sample in samples:
        gold_type = sample['gold_type']
        
        # ç”ŸæˆåŸºäºç±»å‹çš„æ¨¡æ‹Ÿç‰¹å¾ï¼ˆ120ç»´ï¼‰
        features = generate_mock_features(gold_type)
        X.append(features)
        y.append(gold_type)
    
    X = np.array(X)
    y = np.array(y)
    
    print(f"ğŸ“Š ç‰¹å¾ç»´åº¦: {X.shape[1]}")
    print(f"ğŸ“Š æ ·æœ¬æ•°é‡: {X.shape[0]}")
    
    # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
    label_counts = Counter(y)
    print("ğŸ“ˆ æ ‡ç­¾åˆ†å¸ƒ:")
    for label, count in label_counts.items():
        print(f"  {label:<15}: {count:>3} æ ·æœ¬")
    
    # æ ‡ç­¾ç¼–ç 
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    
    # æ•°æ®åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
    )
    
    print(f"ğŸ“Š è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
    print(f"ğŸ“Š æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
    
    # è®­ç»ƒXGBoostæ¨¡å‹
    model = xgb.XGBClassifier(
        objective='multi:softprob',
        n_estimators=200,
        max_depth=6,
        learning_rate=0.1,
        random_state=42,
        use_label_encoder=False,
        eval_metric='mlogloss'
    )
    
    print("ğŸ”„ è®­ç»ƒæ¨¡å‹ä¸­...")
    model.fit(X_train, y_train)
    
    # é¢„æµ‹å’Œè¯„ä¼°
    y_pred = model.predict(X_test)
    
    f1_macro = f1_score(y_test, y_pred, average='macro')
    f1_weighted = f1_score(y_test, y_pred, average='weighted')
    
    print(f"âœ… F1åˆ†æ•° (å®å¹³å‡): {f1_macro:.4f}")
    print(f"âœ… F1åˆ†æ•° (åŠ æƒå¹³å‡): {f1_weighted:.4f}")
    
    # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
    print("\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))
    
    # ä¿å­˜æ¨¡å‹
    model_dir = Path("src/model")
    model_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜XGBoostæ¨¡å‹
    model_path = model_dir / "xgb_model.json"
    model.save_model(str(model_path))
    
    # ä¿å­˜æ ‡ç­¾ç¼–ç å™¨
    joblib.dump(label_encoder, model_dir / "label_encoder.pkl")
    
    # ä¿å­˜ç‰¹å¾åç§°ï¼ˆæ¨¡æ‹Ÿï¼‰
    feature_names = [f"mock_feature_{i}" for i in range(120)]
    with open(model_dir / "feature_names.json", 'w', encoding='utf-8') as f:
        json.dump(feature_names, f, indent=2)
    
    # ä¿å­˜è®­ç»ƒä¿¡æ¯
    training_info = {
        "model_type": "XGBoost",
        "training_samples": len(X_train),
        "test_samples": len(X_test),
        "features": X.shape[1],
        "classes": label_encoder.classes_.tolist(),
        "f1_macro": float(f1_macro),
        "f1_weighted": float(f1_weighted),
        "training_date": "2025-01-12",
        "data_source": "expanded_mock_data",
        "note": "ä½¿ç”¨æ¨¡æ‹Ÿç‰¹å¾çš„å¿«é€Ÿè®­ç»ƒç‰ˆæœ¬"
    }
    
    with open(model_dir / "training_info.json", 'w', encoding='utf-8') as f:
        json.dump(training_info, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜è‡³: {model_path}")
    print(f"ğŸ’¾ è®­ç»ƒä¿¡æ¯å·²ä¿å­˜è‡³: {model_dir / 'training_info.json'}")
    
    print("\nğŸ‰ å¿«é€Ÿè®­ç»ƒå®Œæˆï¼")
    print("ğŸ¯ ä¸‹ä¸€æ­¥: è¿è¡Œ test_trained_model.py æµ‹è¯•æ•ˆæœ")

def generate_mock_features(question_type):
    """ç”ŸæˆåŸºäºé¢˜å‹çš„æ¨¡æ‹Ÿç‰¹å¾"""
    # è®¾ç½®éšæœºç§å­ä»¥ä¿è¯ä¸€è‡´æ€§
    random.seed(hash(question_type) % 1000)
    
    features = []
    
    # åŸºç¡€ç‰¹å¾ (40ç»´)
    base_features = [random.random() for _ in range(40)]
    features.extend(base_features)
    
    # ç±»å‹ç‰¹å®šç‰¹å¾ (80ç»´)
    if question_type == "true_false":
        # åˆ¤æ–­é¢˜ç‰¹å¾ï¼šé«˜answer_pattern_scoreï¼Œä½option_countç­‰
        type_features = [
            0.9 + random.random() * 0.1,  # answer_pattern_score
            0.0,  # option_count
            0.8 + random.random() * 0.2,  # hint_keywords_tf
        ] + [random.random() * 0.3 for _ in range(77)]
    
    elif question_type == "fill_blank":
        # å¡«ç©ºé¢˜ç‰¹å¾ï¼šé«˜blank_markersï¼Œä½option_count
        type_features = [
            0.1 + random.random() * 0.2,  # answer_pattern_score
            0.0,  # option_count
            0.9 + random.random() * 0.1,  # blank_markers
        ] + [random.random() * 0.4 for _ in range(77)]
    
    elif question_type == "multiple_choice":
        # å¤šé€‰é¢˜ç‰¹å¾ï¼šé«˜option_countï¼Œé«˜multi_hints
        type_features = [
            0.5 + random.random() * 0.3,  # answer_pattern_score
            0.7 + random.random() * 0.3,  # option_count
            0.8 + random.random() * 0.2,  # hint_keywords_multi
        ] + [random.random() * 0.6 for _ in range(77)]
    
    elif question_type == "single_choice":
        # å•é€‰é¢˜ç‰¹å¾ï¼šä¸­ç­‰option_countï¼Œä½multi_hints
        type_features = [
            0.6 + random.random() * 0.3,  # answer_pattern_score
            0.5 + random.random() * 0.3,  # option_count
            0.2 + random.random() * 0.3,  # hint_keywords_multi
        ] + [random.random() * 0.5 for _ in range(77)]
    
    else:  # subjective
        # ç®€ç­”é¢˜ç‰¹å¾ï¼šä½answer_patternï¼Œé«˜subjective_hints
        type_features = [
            0.1 + random.random() * 0.2,  # answer_pattern_score
            0.0,  # option_count
            0.8 + random.random() * 0.2,  # hint_keywords_subj
        ] + [random.random() * 0.4 for _ in range(77)]
    
    features.extend(type_features)
    
    return features

if __name__ == "__main__":
    quick_train()
