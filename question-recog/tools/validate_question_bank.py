#!/usr/bin/env python
"""
é¢˜åº“è´¨é‡æ£€æŸ¥å·¥å…· - åœ¨é€‰æ‹©é¢˜åº“æ—¶è¿›è¡Œé¢˜å‹è¯†åˆ«éªŒè¯
"""

import sys
import json
from pathlib import Path
import random

# æ·»åŠ srcåˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.io.readers import DocumentReader
from src.pipeline import QuestionRecognitionPipeline


def validate_question_bank():
    """éªŒè¯é¢˜åº“è´¨é‡å’Œé¢˜å‹è¯†åˆ«å‡†ç¡®æ€§"""
    print("ğŸ” é¢˜åº“è´¨é‡æ£€æŸ¥å·¥å…·")
    print("=" * 50)
    
    # é…ç½®ç³»ç»Ÿ
    config = {
        "thresholds": {
            "min_confidence": 0.4,
            "accept": {
                "single_choice": 0.75,
                "multiple_choice": 0.75,
                "true_false": 0.70,
                "fill_blank": 0.65,
                "subjective": 0.60,
            }
        }
    }
    
    pipeline = QuestionRecognitionPipeline(config)
    reader = DocumentReader()
    
    # æ£€æŸ¥é¢˜åº“ç›®å½•
    tiku_dir = Path("../é¢˜åº“")
    if not tiku_dir.exists():
        print("âŒ é¢˜åº“ç›®å½•ä¸å­˜åœ¨")
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰é¢˜åº“æ–‡ä»¶
    supported_files = []
    for pattern in ["*.xlsx", "*.docx", "*.pdf"]:
        supported_files.extend(tiku_dir.glob(pattern))
    
    if not supported_files:
        print("âŒ æœªæ‰¾åˆ°æ”¯æŒçš„é¢˜åº“æ–‡ä»¶")
        return
    
    print(f"ğŸ“š å‘ç° {len(supported_files)} ä¸ªé¢˜åº“æ–‡ä»¶:")
    for i, file_path in enumerate(supported_files):
        print(f"  {i+1}. {file_path.name}")
    
    # è®©ç”¨æˆ·é€‰æ‹©è¦æ£€æŸ¥çš„é¢˜åº“
    while True:
        try:
            choice = input(f"\nè¯·é€‰æ‹©è¦æ£€æŸ¥çš„é¢˜åº“ (1-{len(supported_files)}, æˆ–è¾“å…¥ 'all' æ£€æŸ¥å…¨éƒ¨): ").strip()
            
            if choice.lower() == 'all':
                selected_files = supported_files
                break
            else:
                idx = int(choice) - 1
                if 0 <= idx < len(supported_files):
                    selected_files = [supported_files[idx]]
                    break
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")
    
    # æ£€æŸ¥æ¯ä¸ªé€‰ä¸­çš„é¢˜åº“
    for file_path in selected_files:
        print(f"\n{'='*60}")
        print(f"ğŸ“„ æ£€æŸ¥é¢˜åº“: {file_path.name}")
        print(f"{'='*60}")
        
        try:
            # è¯»å–æ–‡æ¡£
            document = reader.read_document(str(file_path))
            
            # è¯†åˆ«é¢˜å‹
            results = pipeline.process_document(document)
            
            if not results:
                print("âŒ æœªè¯†åˆ«åˆ°ä»»ä½•é¢˜ç›®")
                continue
            
            # ç»Ÿè®¡åˆ†æ
            stats = analyze_results(results)
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            display_statistics(stats, len(results))
            
            # æ˜¾ç¤ºæ ·æœ¬é¢˜ç›®
            display_samples(results, file_path.name)
            
            # è´¨é‡è¯„ä¼°
            quality_assessment(stats, len(results))
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")


def analyze_results(results):
    """åˆ†æè¯†åˆ«ç»“æœ"""
    stats = {
        "type_distribution": {},
        "confidence_levels": {"high": 0, "medium": 0, "low": 0, "very_low": 0},
        "rule_vs_model": {"rule": 0, "model": 0, "unknown": 0},
        "needs_review": 0,
        "confidence_by_type": {}
    }
    
    for result in results:
        qtype = result.final_result.type.value
        confidence = result.final_result.confidence
        
        # é¢˜å‹åˆ†å¸ƒ
        if qtype not in stats["type_distribution"]:
            stats["type_distribution"][qtype] = 0
        stats["type_distribution"][qtype] += 1
        
        # ç½®ä¿¡åº¦åˆ†çº§
        if confidence >= 0.8:
            stats["confidence_levels"]["high"] += 1
        elif confidence >= 0.6:
            stats["confidence_levels"]["medium"] += 1
        elif confidence >= 0.4:
            stats["confidence_levels"]["low"] += 1
        else:
            stats["confidence_levels"]["very_low"] += 1
        
        # è§„åˆ™vsæ¨¡å‹
        if result.rule_decision:
            stats["rule_vs_model"]["rule"] += 1
        elif qtype == "unknown":
            stats["rule_vs_model"]["unknown"] += 1
        else:
            stats["rule_vs_model"]["model"] += 1
        
        # éœ€è¦å¤æ ¸
        if result.final_result.needs_review:
            stats["needs_review"] += 1
        
        # æŒ‰é¢˜å‹ç»Ÿè®¡ç½®ä¿¡åº¦
        if qtype not in stats["confidence_by_type"]:
            stats["confidence_by_type"][qtype] = []
        stats["confidence_by_type"][qtype].append(confidence)
    
    return stats


def display_statistics(stats, total_questions):
    """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
    print(f"ğŸ“Š è¯†åˆ«ç»Ÿè®¡ (æ€»é¢˜ç›®: {total_questions})")
    print("-" * 40)
    
    # é¢˜å‹åˆ†å¸ƒ
    print("ğŸ¯ é¢˜å‹åˆ†å¸ƒ:")
    for qtype, count in sorted(stats["type_distribution"].items(), key=lambda x: x[1], reverse=True):
        percentage = count / total_questions * 100
        print(f"  {qtype:15}: {count:4} é¢˜ ({percentage:5.1f}%)")
    
    # ç½®ä¿¡åº¦åˆ†å¸ƒ
    print(f"\nğŸ“ˆ ç½®ä¿¡åº¦åˆ†å¸ƒ:")
    conf_levels = stats["confidence_levels"]
    print(f"  é«˜ç½®ä¿¡åº¦ (â‰¥0.8): {conf_levels['high']:4} é¢˜ ({conf_levels['high']/total_questions*100:5.1f}%)")
    print(f"  ä¸­ç½®ä¿¡åº¦ (0.6-0.8): {conf_levels['medium']:4} é¢˜ ({conf_levels['medium']/total_questions*100:5.1f}%)")
    print(f"  ä½ç½®ä¿¡åº¦ (0.4-0.6): {conf_levels['low']:4} é¢˜ ({conf_levels['low']/total_questions*100:5.1f}%)")
    print(f"  æä½ç½®ä¿¡åº¦ (<0.4): {conf_levels['very_low']:4} é¢˜ ({conf_levels['very_low']/total_questions*100:5.1f}%)")
    
    # è¯†åˆ«æ–¹å¼
    print(f"\nğŸ”§ è¯†åˆ«æ–¹å¼:")
    rule_model = stats["rule_vs_model"]
    print(f"  è§„åˆ™è¯†åˆ«: {rule_model['rule']:4} é¢˜ ({rule_model['rule']/total_questions*100:5.1f}%)")
    print(f"  æ¨¡å‹è¯†åˆ«: {rule_model['model']:4} é¢˜ ({rule_model['model']/total_questions*100:5.1f}%)")
    print(f"  æœªçŸ¥é¢˜å‹: {rule_model['unknown']:4} é¢˜ ({rule_model['unknown']/total_questions*100:5.1f}%)")
    
    # éœ€è¦å¤æ ¸
    print(f"\nâš ï¸  éœ€è¦å¤æ ¸: {stats['needs_review']:4} é¢˜ ({stats['needs_review']/total_questions*100:5.1f}%)")


def display_samples(results, filename):
    """æ˜¾ç¤ºæ ·æœ¬é¢˜ç›®"""
    print(f"\nğŸ” æ ·æœ¬é¢˜ç›®æ£€æŸ¥:")
    print("-" * 40)
    
    # æŒ‰é¢˜å‹åˆ†ç»„
    by_type = {}
    for result in results:
        qtype = result.final_result.type.value
        if qtype not in by_type:
            by_type[qtype] = []
        by_type[qtype].append(result)
    
    # æ¯ç§é¢˜å‹æ˜¾ç¤º1-2ä¸ªæ ·æœ¬
    for qtype, questions in by_type.items():
        print(f"\nğŸ“ {qtype} æ ·æœ¬:")
        
        # é€‰æ‹©æ ·æœ¬ï¼šä¸€ä¸ªé«˜ç½®ä¿¡åº¦ï¼Œä¸€ä¸ªä½ç½®ä¿¡åº¦
        samples = []
        high_conf = [q for q in questions if q.final_result.confidence >= 0.8]
        low_conf = [q for q in questions if q.final_result.confidence < 0.6]
        
        if high_conf:
            samples.append(random.choice(high_conf))
        if low_conf and len(samples) < 2:
            samples.append(random.choice(low_conf))
        if not samples and questions:
            samples.append(random.choice(questions))
        
        for i, sample in enumerate(samples[:2]):
            confidence = sample.final_result.confidence
            status = "âœ…" if confidence >= 0.7 else "âš ï¸" if confidence >= 0.5 else "âŒ"
            
            print(f"  {status} æ ·æœ¬ {i+1} (ç½®ä¿¡åº¦: {confidence:.3f}):")
            print(f"     é¢˜å¹²: {sample.question.question[:80]}...")
            
            if sample.question.options:
                print(f"     é€‰é¡¹: {len(sample.question.options)} ä¸ª")
                for j, option in enumerate(sample.question.options[:2]):  # åªæ˜¾ç¤ºå‰2ä¸ªé€‰é¡¹
                    print(f"       {chr(65+j)}. {option[:40]}...")
            
            if sample.question.answer_raw:
                print(f"     ç­”æ¡ˆ: {sample.question.answer_raw[:30]}...")
            
            if sample.rule_decision:
                print(f"     è§„åˆ™: {sample.rule_decision.rule_name}")
            
            print()


def quality_assessment(stats, total_questions):
    """è´¨é‡è¯„ä¼°"""
    print(f"\nğŸ“‹ è´¨é‡è¯„ä¼°æŠ¥å‘Š:")
    print("-" * 40)
    
    # è®¡ç®—è´¨é‡æŒ‡æ ‡
    high_conf_rate = stats["confidence_levels"]["high"] / total_questions
    unknown_rate = stats["type_distribution"].get("unknown", 0) / total_questions
    review_rate = stats["needs_review"] / total_questions
    rule_coverage = stats["rule_vs_model"]["rule"] / total_questions
    
    # æ€»ä½“è¯„åˆ†
    score = 0
    max_score = 100
    
    # é«˜ç½®ä¿¡åº¦æ¯”ä¾‹ (30åˆ†)
    if high_conf_rate >= 0.8:
        score += 30
        print("âœ… é«˜ç½®ä¿¡åº¦æ¯”ä¾‹: ä¼˜ç§€ (â‰¥80%)")
    elif high_conf_rate >= 0.6:
        score += 20
        print("âš ï¸  é«˜ç½®ä¿¡åº¦æ¯”ä¾‹: è‰¯å¥½ (60-80%)")
    elif high_conf_rate >= 0.4:
        score += 10
        print("âŒ é«˜ç½®ä¿¡åº¦æ¯”ä¾‹: ä¸€èˆ¬ (40-60%)")
    else:
        print("âŒ é«˜ç½®ä¿¡åº¦æ¯”ä¾‹: è¾ƒå·® (<40%)")
    
    # æœªçŸ¥é¢˜å‹æ¯”ä¾‹ (25åˆ†)
    if unknown_rate <= 0.1:
        score += 25
        print("âœ… æœªçŸ¥é¢˜å‹æ¯”ä¾‹: ä¼˜ç§€ (â‰¤10%)")
    elif unknown_rate <= 0.2:
        score += 15
        print("âš ï¸  æœªçŸ¥é¢˜å‹æ¯”ä¾‹: è‰¯å¥½ (10-20%)")
    elif unknown_rate <= 0.3:
        score += 5
        print("âŒ æœªçŸ¥é¢˜å‹æ¯”ä¾‹: ä¸€èˆ¬ (20-30%)")
    else:
        print("âŒ æœªçŸ¥é¢˜å‹æ¯”ä¾‹: è¾ƒå·® (>30%)")
    
    # éœ€å¤æ ¸æ¯”ä¾‹ (25åˆ†)
    if review_rate <= 0.1:
        score += 25
        print("âœ… éœ€å¤æ ¸æ¯”ä¾‹: ä¼˜ç§€ (â‰¤10%)")
    elif review_rate <= 0.2:
        score += 15
        print("âš ï¸  éœ€å¤æ ¸æ¯”ä¾‹: è‰¯å¥½ (10-20%)")
    elif review_rate <= 0.3:
        score += 5
        print("âŒ éœ€å¤æ ¸æ¯”ä¾‹: ä¸€èˆ¬ (20-30%)")
    else:
        print("âŒ éœ€å¤æ ¸æ¯”ä¾‹: è¾ƒå·® (>30%)")
    
    # è§„åˆ™è¦†ç›–ç‡ (20åˆ†)
    if rule_coverage >= 0.7:
        score += 20
        print("âœ… è§„åˆ™è¦†ç›–ç‡: ä¼˜ç§€ (â‰¥70%)")
    elif rule_coverage >= 0.5:
        score += 15
        print("âš ï¸  è§„åˆ™è¦†ç›–ç‡: è‰¯å¥½ (50-70%)")
    elif rule_coverage >= 0.3:
        score += 10
        print("âŒ è§„åˆ™è¦†ç›–ç‡: ä¸€èˆ¬ (30-50%)")
    else:
        print("âŒ è§„åˆ™è¦†ç›–ç‡: è¾ƒå·® (<30%)")
    
    # æ€»åˆ†å’Œå»ºè®®
    print(f"\nğŸ¯ æ€»ä½“è´¨é‡è¯„åˆ†: {score}/{max_score} åˆ†")
    
    if score >= 80:
        print("ğŸ‰ é¢˜åº“è´¨é‡ä¼˜ç§€ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ï¼")
    elif score >= 60:
        print("ğŸ‘ é¢˜åº“è´¨é‡è‰¯å¥½ï¼Œå»ºè®®å°‘é‡ä¼˜åŒ–åä½¿ç”¨")
    elif score >= 40:
        print("âš ï¸  é¢˜åº“è´¨é‡ä¸€èˆ¬ï¼Œå»ºè®®ä¼˜åŒ–åä½¿ç”¨")
    else:
        print("âŒ é¢˜åº“è´¨é‡è¾ƒå·®ï¼Œå¼ºçƒˆå»ºè®®ä¼˜åŒ–æˆ–é‡æ–°æ•´ç†")
    
    # å…·ä½“å»ºè®®
    print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
    if unknown_rate > 0.2:
        print("  â€¢ æœªçŸ¥é¢˜å‹è¿‡å¤šï¼Œå»ºè®®ä¼˜åŒ–é¢˜ç›®æ ¼å¼æˆ–å¢å¼ºè§„åˆ™")
    if review_rate > 0.2:
        print("  â€¢ éœ€å¤æ ¸é¢˜ç›®è¿‡å¤šï¼Œå»ºè®®äººå·¥æ£€æŸ¥å¹¶ä¼˜åŒ–")
    if high_conf_rate < 0.6:
        print("  â€¢ é«˜ç½®ä¿¡åº¦æ¯”ä¾‹åä½ï¼Œå»ºè®®è®­ç»ƒXGBoostæ¨¡å‹")
    if rule_coverage < 0.5:
        print("  â€¢ è§„åˆ™è¦†ç›–ç‡åä½ï¼Œå»ºè®®ä¼˜åŒ–è§„åˆ™å¼•æ“")


if __name__ == "__main__":
    validate_question_bank()
