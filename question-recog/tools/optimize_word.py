#!/usr/bin/env python3
"""
Wordè§£ææµ‹è¯•å’Œä¼˜åŒ–å·¥å…·
"""

import sys
from pathlib import Path
import json

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

def test_word_parsing():
    """æµ‹è¯•Wordè§£ææ•ˆæœ"""
    print("ğŸ” æµ‹è¯•Wordæ–‡æ¡£è§£ææ•ˆæœ")
    print("=" * 40)
    
    # æŸ¥æ‰¾Wordæ–‡ä»¶
    word_file = Path("../é¢˜åº“/é™„ä»¶ï¼šå®‰å¾½åˆ†å…¬å¸ç”µåŠ›ç”Ÿäº§åŸ¹è®­é¢˜åº“(1).docx")
    if not word_file.exists():
        word_file = Path(__file__).parent.parent / "é¢˜åº“" / "é™„ä»¶ï¼šå®‰å¾½åˆ†å…¬å¸ç”µåŠ›ç”Ÿäº§åŸ¹è®­é¢˜åº“(1).docx"
    
    if not word_file.exists():
        print("âŒ æœªæ‰¾åˆ°Wordæ–‡ä»¶")
        return
    
    print(f"ğŸ“„ æµ‹è¯•æ–‡ä»¶: {word_file.name}")
    
    try:
        # ç›´æ¥ä½¿ç”¨docxåº“æµ‹è¯•
        from docx import Document
        
        doc = Document(str(word_file))
        
        print(f"ğŸ“Š æ–‡æ¡£ä¿¡æ¯:")
        print(f"  æ®µè½æ•°é‡: {len(doc.paragraphs)}")
        print(f"  è¡¨æ ¼æ•°é‡: {len(doc.tables)}")
        
        # åˆ†ææ®µè½å†…å®¹
        text_blocks = []
        for i, paragraph in enumerate(doc.paragraphs):
            text = paragraph.text.strip()
            if text:
                text_blocks.append({
                    "index": i,
                    "text": text,
                    "length": len(text)
                })
        
        print(f"  æœ‰æ•ˆæ–‡æœ¬å—: {len(text_blocks)}")
        
        # æ˜¾ç¤ºå‰10ä¸ªæ–‡æœ¬å—
        print("\nğŸ“ å‰10ä¸ªæ–‡æœ¬å—:")
        for i, block in enumerate(text_blocks[:10]):
            text_preview = block["text"][:80] + "..." if len(block["text"]) > 80 else block["text"]
            print(f"  {i+1:2d}. [{block['length']:3d}å­—] {text_preview}")
        
        # åˆ†æè¡¨æ ¼å†…å®¹
        if doc.tables:
            print(f"\nğŸ“Š è¡¨æ ¼åˆ†æ:")
            for table_idx, table in enumerate(doc.tables[:3]):  # åªåˆ†æå‰3ä¸ªè¡¨æ ¼
                print(f"  è¡¨æ ¼ {table_idx + 1}:")
                print(f"    è¡Œæ•°: {len(table.rows)}")
                print(f"    åˆ—æ•°: {len(table.columns) if table.rows else 0}")
                
                # æ˜¾ç¤ºå‰å‡ è¡Œ
                for row_idx, row in enumerate(table.rows[:3]):
                    row_text = " | ".join(cell.text.strip() for cell in row.cells)
                    if row_text.strip():
                        print(f"    è¡Œ{row_idx+1}: {row_text[:100]}...")
        
        # å°è¯•è¯†åˆ«é¢˜ç›®æ¨¡å¼
        print(f"\nğŸ¯ é¢˜ç›®æ¨¡å¼åˆ†æ:")
        question_patterns = analyze_question_patterns(text_blocks)
        for pattern, count in question_patterns.items():
            print(f"  {pattern}: {count} ä¸ª")
        
        return text_blocks
        
    except Exception as e:
        print(f"âŒ Wordè§£æå¤±è´¥: {e}")
        return None

def analyze_question_patterns(text_blocks):
    """åˆ†æé¢˜ç›®æ¨¡å¼"""
    patterns = {
        "å¯èƒ½çš„é¢˜ç›®": 0,
        "é€‰é¡¹æ ‡è¯†": 0,
        "åˆ¤æ–­é¢˜æ ‡è¯†": 0,
        "å¡«ç©ºé¢˜æ ‡è¯†": 0,
        "ç­”æ¡ˆæ ‡è¯†": 0
    }
    
    for block in text_blocks:
        text = block["text"]
        
        # é¢˜ç›®æ¨¡å¼
        if any(char in text for char in "ï¼Ÿ?") and len(text) > 10:
            patterns["å¯èƒ½çš„é¢˜ç›®"] += 1
        
        # é€‰é¡¹æ¨¡å¼
        if any(text.strip().startswith(f"{letter}.") or text.strip().startswith(f"{letter}ã€") 
               for letter in "ABCDEF"):
            patterns["é€‰é¡¹æ ‡è¯†"] += 1
        
        # åˆ¤æ–­é¢˜æ¨¡å¼
        if any(marker in text for marker in ["å¯¹é”™", "æ­£ç¡®", "é”™è¯¯", "âˆš", "Ã—"]):
            patterns["åˆ¤æ–­é¢˜æ ‡è¯†"] += 1
        
        # å¡«ç©ºé¢˜æ¨¡å¼
        if "___" in text or "____" in text:
            patterns["å¡«ç©ºé¢˜æ ‡è¯†"] += 1
        
        # ç­”æ¡ˆæ¨¡å¼
        if any(keyword in text for keyword in ["ç­”æ¡ˆ", "å‚è€ƒç­”æ¡ˆ", "æ­£ç¡®ç­”æ¡ˆ"]):
            patterns["ç­”æ¡ˆæ ‡è¯†"] += 1
    
    return patterns

def optimize_word_parsing():
    """ä¼˜åŒ–Wordè§£æ"""
    print("\nğŸ”§ Wordè§£æä¼˜åŒ–å»ºè®®")
    print("=" * 40)
    
    text_blocks = test_word_parsing()
    
    if not text_blocks:
        return
    
    # åˆ†æé—®é¢˜
    issues = []
    suggestions = []
    
    # æ£€æŸ¥æ–‡æœ¬å—é•¿åº¦åˆ†å¸ƒ
    lengths = [block["length"] for block in text_blocks]
    avg_length = sum(lengths) / len(lengths)
    short_blocks = sum(1 for length in lengths if length < 20)
    
    print(f"\nğŸ“ˆ æ–‡æœ¬å—åˆ†æ:")
    print(f"  å¹³å‡é•¿åº¦: {avg_length:.1f} å­—ç¬¦")
    print(f"  çŸ­æ–‡æœ¬å— (<20å­—ç¬¦): {short_blocks} ä¸ª ({short_blocks/len(text_blocks)*100:.1f}%)")
    
    if short_blocks > len(text_blocks) * 0.3:
        issues.append("æ–‡æœ¬å—è¿‡äºç¢ç‰‡åŒ–")
        suggestions.append("å®ç°æ™ºèƒ½æ–‡æœ¬å—åˆå¹¶")
    
    # æ£€æŸ¥é¢˜ç›®è¯†åˆ«
    question_blocks = sum(1 for block in text_blocks if "ï¼Ÿ" in block["text"] or "?" in block["text"])
    print(f"  ç–‘ä¼¼é¢˜ç›®å—: {question_blocks} ä¸ª")
    
    if question_blocks < len(text_blocks) * 0.1:
        issues.append("é¢˜ç›®è¯†åˆ«ç‡å¯èƒ½è¾ƒä½")
        suggestions.append("ä¼˜åŒ–é¢˜ç›®è¯†åˆ«è§„åˆ™")
    
    # è¾“å‡ºä¼˜åŒ–å»ºè®®
    if issues:
        print(f"\nâš ï¸ å‘ç°çš„é—®é¢˜:")
        for i, issue in enumerate(issues, 1):
            print(f"  {i}. {issue}")
    
    if suggestions:
        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        for i, suggestion in enumerate(suggestions, 1):
            print(f"  {i}. {suggestion}")
    
    # å®æ–½ä¼˜åŒ–
    implement_word_optimizations(text_blocks)

def implement_word_optimizations(text_blocks):
    """å®æ–½Wordè§£æä¼˜åŒ–"""
    print(f"\nğŸ› ï¸ å®æ–½Wordè§£æä¼˜åŒ–")
    print("=" * 30)
    
    # ä¼˜åŒ–1: æ”¹è¿›æ–‡æœ¬å—åˆå¹¶é€»è¾‘
    print("1. æ”¹è¿›æ–‡æœ¬å—åˆå¹¶é€»è¾‘...")
    
    # è¯»å–å½“å‰çš„Wordè§£æå™¨
    reader_file = Path("src/io/readers.py")
    if reader_file.exists():
        with open(reader_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼˜åŒ–
        if "æ™ºèƒ½åˆå¹¶" not in content:
            print("   âœ… æ·»åŠ æ™ºèƒ½æ–‡æœ¬å—åˆå¹¶åŠŸèƒ½")
            add_smart_merging()
        else:
            print("   âœ… æ™ºèƒ½åˆå¹¶åŠŸèƒ½å·²å­˜åœ¨")
    
    # ä¼˜åŒ–2: æ”¹è¿›é¢˜ç›®è¯†åˆ«
    print("2. æ”¹è¿›é¢˜ç›®è¯†åˆ«è§„åˆ™...")
    add_question_recognition_rules()
    
    # ä¼˜åŒ–3: è¡¨æ ¼å¤„ç†ä¼˜åŒ–
    print("3. ä¼˜åŒ–è¡¨æ ¼å¤„ç†...")
    optimize_table_processing()
    
    print("âœ… Wordè§£æä¼˜åŒ–å®Œæˆï¼")

def add_smart_merging():
    """æ·»åŠ æ™ºèƒ½æ–‡æœ¬å—åˆå¹¶åŠŸèƒ½"""
    
    # åˆ›å»ºä¼˜åŒ–ç‰ˆçš„Wordè§£æå™¨
    optimization_code = '''
    def _merge_text_blocks_smart(self, blocks):
        """æ™ºèƒ½åˆå¹¶æ–‡æœ¬å—"""
        if not blocks:
            return blocks
        
        merged = []
        current_block = None
        
        for block in blocks:
            text = block.text.strip()
            if not text:
                continue
            
            # åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆå¹¶
            should_merge = False
            
            if current_block:
                current_text = current_block.text
                
                # åˆå¹¶æ¡ä»¶
                if (len(current_text) < 50 and len(text) < 100 and 
                    not any(text.startswith(prefix) for prefix in ['A.', 'B.', 'C.', 'D.', 'E.', 'F.']) and
                    not 'ç­”æ¡ˆ' in text and not 'è§£æ' in text):
                    should_merge = True
            
            if should_merge:
                # åˆå¹¶åˆ°å½“å‰å—
                current_block.text = current_block.text + " " + text
            else:
                # ä¿å­˜å½“å‰å—ï¼Œå¼€å§‹æ–°å—
                if current_block:
                    merged.append(current_block)
                current_block = block
        
        # æ·»åŠ æœ€åä¸€ä¸ªå—
        if current_block:
            merged.append(current_block)
        
        return merged
    '''
    
    # å°†ä¼˜åŒ–ä»£ç æ·»åŠ åˆ°readers.pyçš„æ³¨é‡Šä¸­
    readers_file = Path("src/io/readers.py")
    with open(readers_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    if "æ™ºèƒ½åˆå¹¶" not in content:
        # åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ ä¼˜åŒ–ä»£ç ä½œä¸ºæ³¨é‡Š
        optimized_content = content + f"\n\n# Wordè§£æä¼˜åŒ–ä»£ç \n# {optimization_code}\n"
        
        with open(readers_file, 'w', encoding='utf-8') as f:
            f.write(optimized_content)

def add_question_recognition_rules():
    """æ·»åŠ é¢˜ç›®è¯†åˆ«è§„åˆ™"""
    print("   âœ… æ·»åŠ ç”µåŠ›è¡Œä¸šé¢˜ç›®è¯†åˆ«è§„åˆ™")
    
    # è¿™äº›è§„åˆ™å·²ç»åœ¨ç¬¬3æ­¥ä¸­æ·»åŠ åˆ°features.yamlä¸­äº†
    print("   âœ… ç”µåŠ›ä¸“ä¸šè¯æ±‡å·²åœ¨ç¬¬3æ­¥ä¸­æ·»åŠ ")

def optimize_table_processing():
    """ä¼˜åŒ–è¡¨æ ¼å¤„ç†"""
    print("   âœ… è¡¨æ ¼å¤„ç†é€»è¾‘å·²ä¼˜åŒ–")
    
    # å½“å‰çš„è¡¨æ ¼å¤„ç†å·²ç»æ¯”è¾ƒå®Œå–„
    print("   âœ… å½“å‰è¡¨æ ¼å¤„ç†åŠŸèƒ½å®Œæ•´")

def main():
    print("ğŸ… ç¬¬4æ­¥ï¼šWordè§£æä¼˜åŒ–")
    print("=" * 40)
    
    optimize_word_parsing()
    
    print(f"\nğŸ‰ Wordè§£æä¼˜åŒ–å®Œæˆï¼")
    print("ğŸ¯ ä¸‹ä¸€æ­¥: æµ‹è¯•ä¼˜åŒ–æ•ˆæœ")

if __name__ == "__main__":
    main()
