#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒç³»ç»Ÿé¢˜å‹è¯†åˆ«å™¨ - ç»Ÿä¸€æ¥å£
æ”¯æŒåŸå§‹è¯†åˆ«ç³»ç»Ÿå’Œæ™ºèƒ½é‡æ„ç³»ç»Ÿä¸¤ç§æ¨¡å¼
æä¾›æœ€ä½³çš„é¢˜å‹è¯†åˆ«ä½“éªŒ
"""

import sys
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional
import json
import time

class DualSystemRecognizer:
    """åŒç³»ç»Ÿé¢˜å‹è¯†åˆ«å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åŒç³»ç»Ÿ"""
        self.systems = {
            'original': None,    # åŸå§‹è¯†åˆ«ç³»ç»Ÿ
            'rebuilder': None,   # é‡æ„å™¨ç³»ç»Ÿ
            'enhanced': None     # å¢å¼ºè¯†åˆ«ç³»ç»Ÿ
        }
        
        self.performance_stats = {
            'original': {'success_rate': 0.0, 'avg_confidence': 0.0, 'speed': 0.0},
            'rebuilder': {'success_rate': 0.0, 'avg_confidence': 0.0, 'speed': 0.0},
            'enhanced': {'success_rate': 0.0, 'avg_confidence': 0.0, 'speed': 0.0}
        }
        
        self._load_systems()
    
    def _load_systems(self):
        """åŠ è½½å„ä¸ªè¯†åˆ«ç³»ç»Ÿ"""
        try:
            # åŠ è½½åŸå§‹è¯†åˆ«ç³»ç»Ÿ
            sys.path.insert(0, str(Path(__file__).parent / "question-recog"))
            
            # ç›´æ¥å¯¼å…¥mainæ¨¡å—
            import importlib.util
            main_spec = importlib.util.spec_from_file_location(
                "main", Path(__file__).parent / "question-recog" / "main.py"
            )
            main_module = importlib.util.module_from_spec(main_spec)
            main_spec.loader.exec_module(main_module)
            self.systems['original'] = main_module.enhanced_question_classifier
            
            # åŠ è½½é‡æ„å™¨ç³»ç»Ÿ
            rebuilder_spec = importlib.util.spec_from_file_location(
                "rebuilder", Path(__file__).parent / "question-recog" / "æ™ºèƒ½é¢˜ç›®é‡æ„å™¨.py"
            )
            rebuilder_module = importlib.util.module_from_spec(rebuilder_spec)
            rebuilder_spec.loader.exec_module(rebuilder_module)
            self.systems['rebuilder'] = rebuilder_module.QuestionRebuilder()
            
            # åŠ è½½å¢å¼ºè¯†åˆ«ç³»ç»Ÿ
            enhanced_spec = importlib.util.spec_from_file_location(
                "enhanced", Path(__file__).parent / "é«˜ç²¾åº¦é¢˜å‹è¯†åˆ«.py"
            )
            enhanced_module = importlib.util.module_from_spec(enhanced_spec)
            enhanced_spec.loader.exec_module(enhanced_module)
            self.systems['enhanced'] = enhanced_module.detect_question_type_fixed
            
            print("âœ… åŒç³»ç»ŸåŠ è½½æˆåŠŸ")
            
        except Exception as e:
            print(f"âš ï¸ ç³»ç»ŸåŠ è½½è­¦å‘Š: {e}")
    
    def detect_question_type(self, 
                           question_text: str, 
                           answer: str, 
                           options: List[str] = None, 
                           excel_type: str = None,
                           mode: str = 'auto') -> Tuple[str, float, Dict[str, Any]]:
        """
        ç»Ÿä¸€çš„é¢˜å‹è¯†åˆ«æ¥å£
        
        Args:
            question_text: é¢˜ç›®æ–‡æœ¬
            answer: ç­”æ¡ˆ
            options: é€‰é¡¹åˆ—è¡¨
            excel_type: Excelä¸­çš„é¢˜å‹æ ‡è®°
            mode: è¯†åˆ«æ¨¡å¼ ('auto', 'original', 'rebuilder', 'enhanced', 'consensus')
        
        Returns:
            (é¢˜å‹, ç½®ä¿¡åº¦, è¯¦ç»†ä¿¡æ¯)
        """
        
        if mode == 'auto':
            return self._auto_select_best_system(question_text, answer, options, excel_type)
        elif mode == 'consensus':
            return self._consensus_recognition(question_text, answer, options, excel_type)
        else:
            return self._single_system_recognition(question_text, answer, options, excel_type, mode)
    
    def _auto_select_best_system(self, question_text: str, answer: str, options: List[str], excel_type: str) -> Tuple[str, float, Dict[str, Any]]:
        """è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç³»ç»Ÿ"""
        
        # æ ¹æ®é¢˜ç›®ç‰¹å¾é€‰æ‹©æœ€é€‚åˆçš„ç³»ç»Ÿ
        if len(question_text) < 20:
            # çŸ­é¢˜ç›®ï¼Œå¯èƒ½éœ€è¦é‡æ„
            return self._use_rebuilder_system(question_text, answer, options, excel_type)
        elif options and len(options) >= 2:
            # æœ‰é€‰é¡¹çš„é¢˜ç›®ï¼Œä½¿ç”¨å¢å¼ºç³»ç»Ÿ
            return self._use_enhanced_system(question_text, answer, options, excel_type)
        else:
            # å…¶ä»–æƒ…å†µä½¿ç”¨åŸå§‹ç³»ç»Ÿ
            return self._use_original_system(question_text, answer, options, excel_type)
    
    def _consensus_recognition(self, question_text: str, answer: str, options: List[str], excel_type: str) -> Tuple[str, float, Dict[str, Any]]:
        """å…±è¯†è¯†åˆ« - å¤šç³»ç»ŸæŠ•ç¥¨"""
        
        results = {}
        
        # è·å–å„ç³»ç»Ÿçš„è¯†åˆ«ç»“æœ
        try:
            results['original'] = self._use_original_system(question_text, answer, options, excel_type)
        except:
            results['original'] = ('unknown', 0.0, {})
        
        try:
            results['enhanced'] = self._use_enhanced_system(question_text, answer, options, excel_type)
        except:
            results['enhanced'] = ('unknown', 0.0, {})
        
        # åˆ†æå…±è¯†
        predictions = [r[0] for r in results.values() if r[0] != 'unknown']
        confidences = [r[1] for r in results.values() if r[0] != 'unknown']
        
        if not predictions:
            return 'unknown', 0.0, {'method': 'consensus', 'systems': results}
        
        # æŠ•ç¥¨å†³å®š
        from collections import Counter
        vote_counts = Counter(predictions)
        most_common = vote_counts.most_common(1)[0]
        
        if most_common[1] > 1:  # æœ‰å…±è¯†
            consensus_type = most_common[0]
            # è®¡ç®—è¯¥ç±»å‹çš„å¹³å‡ç½®ä¿¡åº¦
            consensus_confidence = sum(r[1] for r in results.values() if r[0] == consensus_type) / most_common[1]
        else:  # æ— å…±è¯†ï¼Œé€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„
            best_result = max(results.values(), key=lambda x: x[1])
            consensus_type = best_result[0]
            consensus_confidence = best_result[1] * 0.8  # é™ä½ç½®ä¿¡åº¦
        
        return consensus_type, consensus_confidence, {
            'method': 'consensus',
            'systems': results,
            'vote_counts': dict(vote_counts)
        }
    
    def _use_original_system(self, question_text: str, answer: str, options: List[str], excel_type: str) -> Tuple[str, float, Dict[str, Any]]:
        """ä½¿ç”¨åŸå§‹ç³»ç»Ÿ"""
        start_time = time.time()
        
        if self.systems['original']:
            q_type, confidence = self.systems['original'](question_text, options or [], answer, excel_type)
            processing_time = time.time() - start_time
            
            return q_type, confidence, {
                'method': 'original',
                'processing_time': processing_time,
                'system': 'question-recog/main.py'
            }
        else:
            return 'unknown', 0.0, {'method': 'original', 'error': 'system_not_loaded'}
    
    def _use_enhanced_system(self, question_text: str, answer: str, options: List[str], excel_type: str) -> Tuple[str, float, Dict[str, Any]]:
        """ä½¿ç”¨å¢å¼ºç³»ç»Ÿ"""
        start_time = time.time()
        
        if self.systems['enhanced']:
            # è½¬æ¢é€‰é¡¹æ ¼å¼ä¸ºå­—å…¸
            options_dict = {}
            if options:
                for i, opt in enumerate(options):
                    key = chr(ord('A') + i)
                    options_dict[key] = opt
            
            # è°ƒç”¨å¢å¼ºç³»ç»Ÿï¼ˆè¿”å›ä¸­æ–‡ç±»å‹åç§°ï¼‰
            chinese_type = self.systems['enhanced'](question_text, answer, options_dict)
            
            # è½¬æ¢ä¸ºè‹±æ–‡ç±»å‹åç§°å’Œç½®ä¿¡åº¦
            type_mapping = {
                'å•é€‰é¢˜': ('single_choice', 0.85),
                'å¤šé€‰é¢˜': ('multiple_choice', 0.85),
                'åˆ¤æ–­é¢˜': ('true_false', 0.90),
                'å¡«ç©ºé¢˜': ('fill_blank', 0.80),
                'ç®€ç­”é¢˜': ('subjective', 0.75),
                'æœªçŸ¥': ('unknown', 0.0)
            }
            
            q_type, confidence = type_mapping.get(chinese_type, ('unknown', 0.0))
            processing_time = time.time() - start_time
            
            return q_type, confidence, {
                'method': 'enhanced',
                'processing_time': processing_time,
                'system': 'é«˜ç²¾åº¦é¢˜å‹è¯†åˆ«.py',
                'chinese_type': chinese_type
            }
        else:
            return 'unknown', 0.0, {'method': 'enhanced', 'error': 'system_not_loaded'}
    
    def _use_rebuilder_system(self, question_text: str, answer: str, options: List[str], excel_type: str) -> Tuple[str, float, Dict[str, Any]]:
        """ä½¿ç”¨é‡æ„å™¨ç³»ç»Ÿ"""
        start_time = time.time()
        
        # å¯¹äºå•ä¸ªé¢˜ç›®ï¼Œç›´æ¥ä½¿ç”¨å¢å¼ºè¯†åˆ«
        # é‡æ„å™¨ä¸»è¦ç”¨äºæ‰¹é‡å¤„ç†Excelæ–‡ä»¶
        return self._use_enhanced_system(question_text, answer, options, excel_type)
    
    def _single_system_recognition(self, question_text: str, answer: str, options: List[str], excel_type: str, mode: str) -> Tuple[str, float, Dict[str, Any]]:
        """å•ç³»ç»Ÿè¯†åˆ«"""
        
        if mode == 'original':
            return self._use_original_system(question_text, answer, options, excel_type)
        elif mode == 'enhanced':
            return self._use_enhanced_system(question_text, answer, options, excel_type)
        elif mode == 'rebuilder':
            return self._use_rebuilder_system(question_text, answer, options, excel_type)
        else:
            return 'unknown', 0.0, {'method': mode, 'error': 'invalid_mode'}
    
    def batch_process_excel(self, excel_path: str, mode: str = 'rebuilder', output_path: str = None) -> Dict[str, Any]:
        """æ‰¹é‡å¤„ç†Excelæ–‡ä»¶"""
        
        if mode == 'rebuilder' and self.systems['rebuilder']:
            # ä½¿ç”¨é‡æ„å™¨å¤„ç†
            questions = self.systems['rebuilder'].process_excel_file(excel_path)
            
            # å¯¹é‡æ„åçš„é¢˜ç›®è¿›è¡Œè¯†åˆ«
            results = []
            for i, q in enumerate(questions):
                q_type, confidence, details = self.detect_question_type(
                    q['question'], q['answer'], q['options'], mode='enhanced'
                )
                
                results.append({
                    'id': i + 1,
                    'question': q['question'],
                    'options': q['options'],
                    'answer': q['answer'],
                    'predicted_type': q_type,
                    'confidence': confidence,
                    'quality_score': q.get('quality_score', 0.0),
                    'details': details
                })
            
            # ä¿å­˜ç»“æœ
            if output_path:
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
            
            return {
                'total_questions': len(results),
                'results': results,
                'method': 'rebuilder_batch',
                'source_file': excel_path
            }
        
        else:
            # ä½¿ç”¨åŸå§‹æ–¹æ³•å¤„ç†
            import pandas as pd
            df = pd.read_excel(excel_path)
            
            results = []
            for i, row in df.iterrows():
                question = str(row.get('é¢˜ç›®ï¼ˆå¿…å¡«ï¼‰ï¼š', ''))
                answer = str(row.get('æ­£ç¡®ç­”æ¡ˆï¼ˆå¿…å¡«ï¼‰', ''))
                
                # æå–é€‰é¡¹
                options = []
                for opt_col in ['é€‰é¡¹Aï¼ˆå¿…å¡«ï¼‰', 'é€‰é¡¹Bï¼ˆå¿…å¡«ï¼‰', 'é€‰é¡¹C', 'é€‰é¡¹D']:
                    if opt_col in df.columns and not pd.isna(row[opt_col]):
                        options.append(str(row[opt_col]))
                
                q_type, confidence, details = self.detect_question_type(
                    question, answer, options, mode=mode
                )
                
                results.append({
                    'id': i + 1,
                    'question': question,
                    'options': options,
                    'answer': answer,
                    'predicted_type': q_type,
                    'confidence': confidence,
                    'details': details
                })
            
            # ä¿å­˜ç»“æœ
            if output_path:
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
            
            return {
                'total_questions': len(results),
                'results': results,
                'method': f'{mode}_batch',
                'source_file': excel_path
            }
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        return {
            'loaded_systems': {k: v is not None for k, v in self.systems.items()},
            'performance_stats': self.performance_stats,
            'available_modes': ['auto', 'original', 'enhanced', 'rebuilder', 'consensus']
        }
    
    def benchmark_systems(self, test_questions: List[Dict]) -> Dict[str, Any]:
        """åŸºå‡†æµ‹è¯•å„ç³»ç»Ÿæ€§èƒ½"""
        
        benchmark_results = {}
        
        for system_name in ['original', 'enhanced']:
            if self.systems.get(system_name.split('_')[0]):
                results = []
                total_time = 0
                
                for q in test_questions:
                    start_time = time.time()
                    q_type, confidence, details = self.detect_question_type(
                        q['question'], q['answer'], q.get('options', []), mode=system_name
                    )
                    processing_time = time.time() - start_time
                    total_time += processing_time
                    
                    results.append({
                        'predicted': q_type,
                        'confidence': confidence,
                        'time': processing_time,
                        'correct': q_type == q.get('expected_type', 'unknown')
                    })
                
                accuracy = sum(1 for r in results if r['correct']) / len(results) if results else 0
                avg_confidence = sum(r['confidence'] for r in results) / len(results) if results else 0
                avg_time = total_time / len(results) if results else 0
                
                benchmark_results[system_name] = {
                    'accuracy': accuracy,
                    'avg_confidence': avg_confidence,
                    'avg_processing_time': avg_time,
                    'total_questions': len(results),
                    'results': results
                }
        
        return benchmark_results

# å…¨å±€å®ä¾‹
dual_recognizer = DualSystemRecognizer()

def detect_question_type_dual(question_text: str, 
                             answer: str, 
                             options: List[str] = None, 
                             excel_type: str = None,
                             mode: str = 'auto') -> Tuple[str, float]:
    """
    åŒç³»ç»Ÿé¢˜å‹è¯†åˆ«çš„ç®€åŒ–æ¥å£
    
    Args:
        question_text: é¢˜ç›®æ–‡æœ¬
        answer: ç­”æ¡ˆ
        options: é€‰é¡¹åˆ—è¡¨
        excel_type: Excelä¸­çš„é¢˜å‹æ ‡è®°
        mode: è¯†åˆ«æ¨¡å¼
    
    Returns:
        (é¢˜å‹, ç½®ä¿¡åº¦)
    """
    q_type, confidence, _ = dual_recognizer.detect_question_type(
        question_text, answer, options, excel_type, mode
    )
    return q_type, confidence

def test_dual_system():
    """æµ‹è¯•åŒç³»ç»Ÿ"""
    print("ğŸ§ª åŒç³»ç»Ÿæµ‹è¯•")
    print("=" * 50)
    
    test_cases = [
        {
            'question': 'ä¸‹åˆ—å“ªä¸ªæ˜¯æ­£ç¡®çš„ï¼Ÿ',
            'answer': 'A',
            'options': ['A: é€‰é¡¹A', 'B: é€‰é¡¹B', 'C: é€‰é¡¹C', 'D: é€‰é¡¹D'],
            'expected': 'single_choice'
        },
        {
            'question': 'ä»¥ä¸‹è¯´æ³•æ­£ç¡®çš„æ˜¯ï¼Ÿ',
            'answer': 'ABC',
            'options': ['A: é€‰é¡¹A', 'B: é€‰é¡¹B', 'C: é€‰é¡¹C', 'D: é€‰é¡¹D'],
            'expected': 'multiple_choice'
        },
        {
            'question': 'åœ°çƒæ˜¯åœ†çš„ã€‚',
            'answer': 'å¯¹',
            'options': [],
            'expected': 'true_false'
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i}:")
        print(f"  é¢˜ç›®: {case['question']}")
        print(f"  ç­”æ¡ˆ: {case['answer']}")
        print(f"  é€‰é¡¹: {len(case['options'])}ä¸ª")
        
        # æµ‹è¯•ä¸åŒæ¨¡å¼
        for mode in ['auto', 'original', 'enhanced', 'consensus']:
            try:
                q_type, confidence, details = dual_recognizer.detect_question_type(
                    case['question'], case['answer'], case['options'], mode=mode
                )
                
                correct = "âœ…" if q_type == case['expected'] else "âŒ"
                print(f"  {mode:10}: {q_type:15} ({confidence:.2f}) {correct}")
                
            except Exception as e:
                print(f"  {mode:10}: é”™è¯¯ - {e}")
    
    # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
    status = dual_recognizer.get_system_status()
    print(f"\nğŸ“Š ç³»ç»ŸçŠ¶æ€:")
    for system, loaded in status['loaded_systems'].items():
        status_icon = "âœ…" if loaded else "âŒ"
        print(f"  {system:10}: {status_icon}")

if __name__ == "__main__":
    test_dual_system()
