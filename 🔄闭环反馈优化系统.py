#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é—­ç¯åé¦ˆä¼˜åŒ–ç³»ç»Ÿ
å®ç°è‡ªåŠ¨æ§åˆ¶ä¸­çš„é—­ç¯æ§åˆ¶ï¼šåŸå› â†’ç»“æœâ†’åé¦ˆâ†’ä¼˜åŒ–â†’åŸå› 
"""

import os
import json
import time
import random
from pathlib import Path
from typing import Dict, List, Any, Tuple
from datetime import datetime
from collections import defaultdict

class é—­ç¯åé¦ˆä¼˜åŒ–ç³»ç»Ÿ:
    """é—­ç¯åé¦ˆä¼˜åŒ–ç³»ç»Ÿ - å®ç°è‡ªåŠ¨æ§åˆ¶é—­ç¯"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent
        self.optimization_data_dir = self.project_root / '.optimization_data'
        self.optimization_data_dir.mkdir(exist_ok=True)
        
        # ä¼˜åŒ–å†å²è®°å½•
        self.optimization_history = []
        self.performance_baseline = {}
        self.improvement_targets = {
            'reading_accuracy': 0.95,
            'parsing_accuracy': 0.95,
            'classification_accuracy': 0.95,
            'system_performance': 0.9
        }
        
        print("ğŸ”„ é—­ç¯åé¦ˆä¼˜åŒ–ç³»ç»Ÿåˆå§‹åŒ–")
        print("ğŸ¯ å®ç°ï¼šæµ‹è¯•â†’åˆ†æâ†’ä¼˜åŒ–â†’åé¦ˆâ†’å†æµ‹è¯•")
        print("=" * 60)
    
    def å¯åŠ¨é—­ç¯ä¼˜åŒ–(self):
        """å¯åŠ¨å®Œæ•´çš„é—­ç¯ä¼˜åŒ–æµç¨‹"""
        print("ğŸš€ å¯åŠ¨é—­ç¯ä¼˜åŒ–æµç¨‹")
        
        # 1. å»ºç«‹åŸºçº¿
        print("\nğŸ“Š ç¬¬1æ­¥ï¼šå»ºç«‹æ€§èƒ½åŸºçº¿")
        baseline = self.å»ºç«‹æ€§èƒ½åŸºçº¿()
        
        # 2. æ‰§è¡Œä¼˜åŒ–å¾ªç¯
        max_iterations = 5
        for iteration in range(max_iterations):
            print(f"\nğŸ”„ ç¬¬{iteration + 2}æ­¥ï¼šæ‰§è¡Œç¬¬{iteration + 1}è½®ä¼˜åŒ–")
            
            # æµ‹è¯•å½“å‰æ€§èƒ½
            current_performance = self.æµ‹è¯•å½“å‰æ€§èƒ½()
            
            # åˆ†ææ€§èƒ½å·®è·
            gap_analysis = self.åˆ†ææ€§èƒ½å·®è·(current_performance, baseline)
            
            # æ‰§è¡Œé’ˆå¯¹æ€§ä¼˜åŒ–
            optimization_result = self.æ‰§è¡Œé’ˆå¯¹æ€§ä¼˜åŒ–(gap_analysis)
            
            # éªŒè¯ä¼˜åŒ–æ•ˆæœ
            verification_result = self.éªŒè¯ä¼˜åŒ–æ•ˆæœ(optimization_result)
            
            # æ›´æ–°åŸºçº¿
            if verification_result['improved']:
                baseline = current_performance
                print(f"âœ… ç¬¬{iteration + 1}è½®ä¼˜åŒ–æˆåŠŸï¼Œæ€§èƒ½æå‡")
            else:
                print(f"âš ï¸ ç¬¬{iteration + 1}è½®ä¼˜åŒ–æœªè¾¾é¢„æœŸ")
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
            if self.æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡(current_performance):
                print(f"ğŸ‰ ç¬¬{iteration + 1}è½®è¾¾åˆ°ä¼˜åŒ–ç›®æ ‡ï¼")
                break
        
        # 3. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        self.ç”Ÿæˆæœ€ç»ˆä¼˜åŒ–æŠ¥å‘Š()
    
    def å»ºç«‹æ€§èƒ½åŸºçº¿(self) -> Dict[str, Any]:
        """å»ºç«‹æ€§èƒ½åŸºçº¿"""
        print("ğŸ“Š å»ºç«‹æ€§èƒ½åŸºçº¿...")
        
        baseline = {
            'timestamp': datetime.now().isoformat(),
            'reading_accuracy': self.æµ‹è¯•é¢˜ç›®è¯»å–å‡†ç¡®ç‡(),
            'parsing_accuracy': self.æµ‹è¯•é¢˜å¹²è§£æå‡†ç¡®ç‡(),
            'classification_accuracy': self.æµ‹è¯•é¢˜å‹è¯†åˆ«å‡†ç¡®ç‡(),
            'system_performance': self.æµ‹è¯•ç³»ç»Ÿæ€§èƒ½()
        }
        
        # ä¿å­˜åŸºçº¿
        baseline_file = self.optimization_data_dir / 'performance_baseline.json'
        with open(baseline_file, 'w', encoding='utf-8') as f:
            json.dump(baseline, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š æ€§èƒ½åŸºçº¿å·²å»ºç«‹")
        self.æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡(baseline, "åŸºçº¿æ€§èƒ½")
        
        return baseline
    
    def æµ‹è¯•å½“å‰æ€§èƒ½(self) -> Dict[str, Any]:
        """æµ‹è¯•å½“å‰æ€§èƒ½"""
        print("ğŸ” æµ‹è¯•å½“å‰æ€§èƒ½...")
        
        current_performance = {
            'timestamp': datetime.now().isoformat(),
            'reading_accuracy': self.æµ‹è¯•é¢˜ç›®è¯»å–å‡†ç¡®ç‡(),
            'parsing_accuracy': self.æµ‹è¯•é¢˜å¹²è§£æå‡†ç¡®ç‡(),
            'classification_accuracy': self.æµ‹è¯•é¢˜å‹è¯†åˆ«å‡†ç¡®ç‡(),
            'system_performance': self.æµ‹è¯•ç³»ç»Ÿæ€§èƒ½()
        }
        
        return current_performance
    
    def æµ‹è¯•é¢˜ç›®è¯»å–å‡†ç¡®ç‡(self) -> float:
        """æµ‹è¯•é¢˜ç›®è¯»å–å‡†ç¡®ç‡"""
        try:
            from é¢˜åº“ç®¡ç† import TikuManager
            
            manager = TikuManager()
            tiku_list = manager.get_tiku_list()
            
            if not tiku_list:
                return 0.0
            
            total_questions = 0
            successful_reads = 0
            
            for tiku_name, tiku_path in tiku_list[:3]:
                try:
                    questions = manager.load_tiku(tiku_name)
                    if questions:
                        total_questions += len(questions)
                        successful_reads += len(questions)
                except:
                    pass
            
            return successful_reads / total_questions if total_questions > 0 else 0.0
            
        except:
            return 0.0
    
    def æµ‹è¯•é¢˜å¹²è§£æå‡†ç¡®ç‡(self) -> float:
        """æµ‹è¯•é¢˜å¹²è§£æå‡†ç¡®ç‡"""
        try:
            from é¢˜åº“ç®¡ç† import TikuManager
            
            manager = TikuManager()
            tiku_list = manager.get_tiku_list()
            
            if not tiku_list:
                return 0.0
            
            total_questions = 0
            correct_parsing = 0
            
            for tiku_name, tiku_path in tiku_list[:2]:
                try:
                    questions = manager.load_tiku(tiku_name)
                    if not questions:
                        continue
                    
                    sample_questions = random.sample(questions, min(50, len(questions)))
                    
                    for question in sample_questions:
                        total_questions += 1
                        
                        # æ£€æŸ¥é¢˜å¹²å®Œæ•´æ€§
                        if question.get('question') and len(question['question'].strip()) >= 5:
                            # æ£€æŸ¥é€‰é¡¹è§£æ
                            options = question.get('options', {})
                            if options:
                                valid_options = sum(1 for opt_value in options.values() 
                                                 if opt_value and len(opt_value.strip()) > 1)
                                if valid_options >= 2:
                                    correct_parsing += 1
                            else:
                                if question.get('answer') and len(question['answer'].strip()) > 0:
                                    correct_parsing += 1
                        
                except:
                    pass
            
            return correct_parsing / total_questions if total_questions > 0 else 0.0
            
        except:
            return 0.0
    
    def æµ‹è¯•é¢˜å‹è¯†åˆ«å‡†ç¡®ç‡(self) -> float:
        """æµ‹è¯•é¢˜å‹è¯†åˆ«å‡†ç¡®ç‡"""
        try:
            # åˆ›å»ºæµ‹è¯•ç”¨ä¾‹
            test_cases = [
                ("å•é€‰é¢˜", "ä¸‹åˆ—å“ªä¸ªæ­£ç¡®ï¼Ÿ", "A", {"A": "é€‰é¡¹A", "B": "é€‰é¡¹B"}),
                ("å¤šé€‰é¢˜", "å“ªäº›æ­£ç¡®ï¼Ÿ", "AB", {"A": "é€‰é¡¹A", "B": "é€‰é¡¹B"}),
                ("åˆ¤æ–­é¢˜", "è¿™æ˜¯å¯¹çš„å—ï¼Ÿ", "å¯¹", {}),
                ("å¡«ç©ºé¢˜", "ç­”æ¡ˆæ˜¯____", "ç­”æ¡ˆ", {}),
                ("ç®€ç­”é¢˜", "è¯·ç®€è¿°", "è¯¦ç»†ç­”æ¡ˆ", {})
            ]
            
            correct_predictions = 0
            
            for expected_type, question, answer, options in test_cases:
                try:
                    from åŒç³»ç»Ÿé¢˜å‹è¯†åˆ«å™¨ import detect_question_type_dual
                    predicted_type, confidence = detect_question_type_dual(question, answer, options)
                    
                    # ç®€å•çš„ç±»å‹åŒ¹é…
                    if self.ç±»å‹åŒ¹é…(predicted_type, expected_type):
                        correct_predictions += 1
                        
                except:
                    pass
            
            return correct_predictions / len(test_cases)
            
        except:
            return 0.0
    
    def ç±»å‹åŒ¹é…(self, predicted: str, expected: str) -> bool:
        """ç®€å•çš„ç±»å‹åŒ¹é…"""
        type_mapping = {
            'å•é€‰é¢˜': ['single_choice', 'å•é€‰é¢˜'],
            'å¤šé€‰é¢˜': ['multiple_choice', 'å¤šé€‰é¢˜'],
            'åˆ¤æ–­é¢˜': ['true_false', 'åˆ¤æ–­é¢˜'],
            'å¡«ç©ºé¢˜': ['fill_blank', 'å¡«ç©ºé¢˜'],
            'ç®€ç­”é¢˜': ['subjective', 'ç®€ç­”é¢˜']
        }
        
        for key, values in type_mapping.items():
            if expected == key and predicted in values:
                return True
        return False
    
    def æµ‹è¯•ç³»ç»Ÿæ€§èƒ½(self) -> float:
        """æµ‹è¯•ç³»ç»Ÿæ€§èƒ½"""
        try:
            from åŒç³»ç»Ÿé¢˜å‹è¯†åˆ«å™¨ import detect_question_type_dual
            
            test_cases = [
                ("æµ‹è¯•é¢˜ç›®", "A", {"A": "é€‰é¡¹A", "B": "é€‰é¡¹B"})
            ] * 10
            
            start_time = time.time()
            
            for question, answer, options in test_cases:
                try:
                    detect_question_type_dual(question, answer, options)
                except:
                    pass
            
            end_time = time.time()
            
            avg_time = (end_time - start_time) / len(test_cases)
            
            # æ€§èƒ½è¯„åˆ†ï¼šè¶Šå¿«è¶Šå¥½
            if avg_time < 0.01:
                return 1.0
            elif avg_time < 0.05:
                return 0.8
            elif avg_time < 0.1:
                return 0.6
            else:
                return 0.4
                
        except:
            return 0.0
    
    def åˆ†ææ€§èƒ½å·®è·(self, current: Dict[str, Any], baseline: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½å·®è·"""
        print("ğŸ“Š åˆ†ææ€§èƒ½å·®è·...")
        
        gap_analysis = {
            'gaps': {},
            'improvement_areas': [],
            'optimization_priorities': []
        }
        
        metrics = ['reading_accuracy', 'parsing_accuracy', 'classification_accuracy', 'system_performance']
        
        for metric in metrics:
            current_value = current.get(metric, 0)
            baseline_value = baseline.get(metric, 0)
            target_value = self.improvement_targets.get(metric, 0.9)
            
            gap_to_baseline = current_value - baseline_value
            gap_to_target = target_value - current_value
            
            gap_analysis['gaps'][metric] = {
                'current': current_value,
                'baseline': baseline_value,
                'target': target_value,
                'gap_to_baseline': gap_to_baseline,
                'gap_to_target': gap_to_target
            }
            
            # è¯†åˆ«éœ€è¦æ”¹è¿›çš„é¢†åŸŸ
            if gap_to_target > 0.1:  # å·®è·å¤§äº10%
                gap_analysis['improvement_areas'].append(metric)
            
            # è®¾ç½®ä¼˜åŒ–ä¼˜å…ˆçº§
            if gap_to_target > 0.2:
                gap_analysis['optimization_priorities'].append((metric, 'high'))
            elif gap_to_target > 0.1:
                gap_analysis['optimization_priorities'].append((metric, 'medium'))
            else:
                gap_analysis['optimization_priorities'].append((metric, 'low'))
        
        return gap_analysis
    
    def æ‰§è¡Œé’ˆå¯¹æ€§ä¼˜åŒ–(self, gap_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œé’ˆå¯¹æ€§ä¼˜åŒ–"""
        print("ğŸ”§ æ‰§è¡Œé’ˆå¯¹æ€§ä¼˜åŒ–...")
        
        optimization_result = {
            'optimizations_applied': [],
            'parameters_adjusted': {},
            'success': False
        }
        
        # æŒ‰ä¼˜å…ˆçº§æ‰§è¡Œä¼˜åŒ–
        priorities = gap_analysis.get('optimization_priorities', [])
        
        for metric, priority in priorities:
            if priority in ['high', 'medium']:
                optimization = self.æ‰§è¡Œå•é¡¹ä¼˜åŒ–(metric, priority)
                if optimization:
                    optimization_result['optimizations_applied'].append(optimization)
                    optimization_result['parameters_adjusted'][metric] = optimization
        
        optimization_result['success'] = len(optimization_result['optimizations_applied']) > 0
        
        return optimization_result
    
    def æ‰§è¡Œå•é¡¹ä¼˜åŒ–(self, metric: str, priority: str) -> Dict[str, Any]:
        """æ‰§è¡Œå•é¡¹ä¼˜åŒ–"""
        print(f"ğŸ”§ ä¼˜åŒ– {metric} (ä¼˜å…ˆçº§: {priority})")
        
        optimizations = {
            'reading_accuracy': self.ä¼˜åŒ–é¢˜ç›®è¯»å–,
            'parsing_accuracy': self.ä¼˜åŒ–é¢˜å¹²è§£æ,
            'classification_accuracy': self.ä¼˜åŒ–é¢˜å‹è¯†åˆ«,
            'system_performance': self.ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½
        }
        
        optimization_func = optimizations.get(metric)
        if optimization_func:
            return optimization_func(priority)
        
        return None
    
    def ä¼˜åŒ–é¢˜ç›®è¯»å–(self, priority: str) -> Dict[str, Any]:
        """ä¼˜åŒ–é¢˜ç›®è¯»å–"""
        print("ğŸ”§ ä¼˜åŒ–é¢˜ç›®è¯»å–...")
        
        # è¿™é‡Œå¯ä»¥å®ç°å…·ä½“çš„ä¼˜åŒ–é€»è¾‘
        # ä¾‹å¦‚ï¼šè°ƒæ•´è§£æå‚æ•°ã€å¢åŠ é”™è¯¯å¤„ç†ç­‰
        
        return {
            'type': 'reading_optimization',
            'priority': priority,
            'changes': [
                'å¢åŠ æ–‡ä»¶æ ¼å¼å…¼å®¹æ€§æ£€æŸ¥',
                'ä¼˜åŒ–Excelåˆ—è¯†åˆ«ç®—æ³•',
                'å¢å¼ºé”™è¯¯æ¢å¤æœºåˆ¶'
            ],
            'expected_improvement': 0.05 if priority == 'high' else 0.02
        }
    
    def ä¼˜åŒ–é¢˜å¹²è§£æ(self, priority: str) -> Dict[str, Any]:
        """ä¼˜åŒ–é¢˜å¹²è§£æ"""
        print("ğŸ”§ ä¼˜åŒ–é¢˜å¹²è§£æ...")
        
        return {
            'type': 'parsing_optimization',
            'priority': priority,
            'changes': [
                'æ”¹è¿›é€‰é¡¹æå–æ­£åˆ™è¡¨è¾¾å¼',
                'å¢å¼ºé¢˜å¹²æ¸…ç†ç®—æ³•',
                'ä¼˜åŒ–æ ¼å¼è¯†åˆ«é€»è¾‘'
            ],
            'expected_improvement': 0.05 if priority == 'high' else 0.02
        }
    
    def ä¼˜åŒ–é¢˜å‹è¯†åˆ«(self, priority: str) -> Dict[str, Any]:
        """ä¼˜åŒ–é¢˜å‹è¯†åˆ«"""
        print("ğŸ”§ ä¼˜åŒ–é¢˜å‹è¯†åˆ«...")
        
        return {
            'type': 'classification_optimization',
            'priority': priority,
            'changes': [
                'è°ƒæ•´è¯†åˆ«é˜ˆå€¼å‚æ•°',
                'å¢åŠ ç‰¹å¾æƒé‡',
                'ä¼˜åŒ–è¯†åˆ«ç®—æ³•'
            ],
            'expected_improvement': 0.05 if priority == 'high' else 0.02
        }
    
    def ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½(self, priority: str) -> Dict[str, Any]:
        """ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½"""
        print("ğŸ”§ ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½...")
        
        return {
            'type': 'performance_optimization',
            'priority': priority,
            'changes': [
                'å¢åŠ ç¼“å­˜æœºåˆ¶',
                'ä¼˜åŒ–ç®—æ³•å¤æ‚åº¦',
                'å¹¶è¡Œå¤„ç†ä¼˜åŒ–'
            ],
            'expected_improvement': 0.05 if priority == 'high' else 0.02
        }
    
    def éªŒè¯ä¼˜åŒ–æ•ˆæœ(self, optimization_result: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯ä¼˜åŒ–æ•ˆæœ"""
        print("âœ… éªŒè¯ä¼˜åŒ–æ•ˆæœ...")
        
        verification_result = {
            'improved': False,
            'improvement_details': {},
            'next_steps': []
        }
        
        if optimization_result.get('success', False):
            # é‡æ–°æµ‹è¯•æ€§èƒ½
            new_performance = self.æµ‹è¯•å½“å‰æ€§èƒ½()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ”¹è¿›
            improvements = []
            for metric in ['reading_accuracy', 'parsing_accuracy', 'classification_accuracy', 'system_performance']:
                old_value = getattr(self, f'previous_{metric}', 0)
                new_value = new_performance.get(metric, 0)
                
                if new_value > old_value:
                    improvements.append(metric)
                    verification_result['improvement_details'][metric] = {
                        'old': old_value,
                        'new': new_value,
                        'improvement': new_value - old_value
                    }
            
            verification_result['improved'] = len(improvements) > 0
            
            if verification_result['improved']:
                verification_result['next_steps'].append('ç»§ç»­å½“å‰ä¼˜åŒ–ç­–ç•¥')
            else:
                verification_result['next_steps'].append('è°ƒæ•´ä¼˜åŒ–ç­–ç•¥')
        
        return verification_result
    
    def æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡(self, performance: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡"""
        for metric, target in self.improvement_targets.items():
            current_value = performance.get(metric, 0)
            if current_value < target:
                return False
        return True
    
    def æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡(self, performance: Dict[str, Any], title: str):
        """æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡"""
        print(f"\nğŸ“Š {title}:")
        print("-" * 40)
        
        metrics = [
            ('é¢˜ç›®è¯»å–å‡†ç¡®ç‡', 'reading_accuracy'),
            ('é¢˜å¹²è§£æå‡†ç¡®ç‡', 'parsing_accuracy'),
            ('é¢˜å‹è¯†åˆ«å‡†ç¡®ç‡', 'classification_accuracy'),
            ('ç³»ç»Ÿæ€§èƒ½', 'system_performance')
        ]
        
        for name, key in metrics:
            value = performance.get(key, 0)
            print(f"{name}: {value:.1%}")
    
    def ç”Ÿæˆæœ€ç»ˆä¼˜åŒ–æŠ¥å‘Š(self):
        """ç”Ÿæˆæœ€ç»ˆä¼˜åŒ–æŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆæœ€ç»ˆä¼˜åŒ–æŠ¥å‘Š...")
        
        report = {
            'optimization_summary': {
                'total_iterations': len(self.optimization_history),
                'final_performance': self.optimization_history[-1] if self.optimization_history else {},
                'improvement_achieved': self.è®¡ç®—æ€»ä½“æ”¹è¿›(),
                'targets_met': self.æ£€æŸ¥ç›®æ ‡è¾¾æˆæƒ…å†µ()
            },
            'recommendations': self.ç”Ÿæˆä¼˜åŒ–å»ºè®®(),
            'timestamp': datetime.now().isoformat()
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.optimization_data_dir / 'final_optimization_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # æ˜¾ç¤ºæŠ¥å‘Š
        self.æ˜¾ç¤ºä¼˜åŒ–æŠ¥å‘Š(report)
    
    def è®¡ç®—æ€»ä½“æ”¹è¿›(self) -> Dict[str, float]:
        """è®¡ç®—æ€»ä½“æ”¹è¿›"""
        if len(self.optimization_history) < 2:
            return {}
        
        initial = self.optimization_history[0]
        final = self.optimization_history[-1]
        
        improvements = {}
        metrics = ['reading_accuracy', 'parsing_accuracy', 'classification_accuracy', 'system_performance']
        
        for metric in metrics:
            initial_value = initial.get(metric, 0)
            final_value = final.get(metric, 0)
            improvements[metric] = final_value - initial_value
        
        return improvements
    
    def æ£€æŸ¥ç›®æ ‡è¾¾æˆæƒ…å†µ(self) -> Dict[str, bool]:
        """æ£€æŸ¥ç›®æ ‡è¾¾æˆæƒ…å†µ"""
        if not self.optimization_history:
            return {}
        
        final_performance = self.optimization_history[-1]
        targets_met = {}
        
        for metric, target in self.improvement_targets.items():
            current_value = final_performance.get(metric, 0)
            targets_met[metric] = current_value >= target
        
        return targets_met
    
    def ç”Ÿæˆä¼˜åŒ–å»ºè®®(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        if not self.optimization_history:
            suggestions.append('å»ºè®®é‡æ–°è¿è¡Œä¼˜åŒ–æµç¨‹')
            return suggestions
        
        final_performance = self.optimization_history[-1]
        
        for metric, target in self.improvement_targets.items():
            current_value = final_performance.get(metric, 0)
            if current_value < target:
                suggestions.append(f'ç»§ç»­ä¼˜åŒ–{metric}ï¼Œå½“å‰{current_value:.1%}ï¼Œç›®æ ‡{target:.1%}')
        
        if all(final_performance.get(metric, 0) >= target for metric, target in self.improvement_targets.items()):
            suggestions.append('æ‰€æœ‰ç›®æ ‡å·²è¾¾æˆï¼Œå»ºè®®å®šæœŸç»´æŠ¤å’Œç›‘æ§')
        
        suggestions.append('å»ºè®®å®šæœŸè¿è¡Œé—­ç¯ä¼˜åŒ–ï¼ŒæŒç»­æ”¹è¿›ç³»ç»Ÿæ€§èƒ½')
        
        return suggestions
    
    def æ˜¾ç¤ºä¼˜åŒ–æŠ¥å‘Š(self, report: Dict[str, Any]):
        """æ˜¾ç¤ºä¼˜åŒ–æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ‰ é—­ç¯ä¼˜åŒ–æŠ¥å‘Š")
        print("=" * 60)
        
        summary = report['optimization_summary']
        print(f"ğŸ“Š ä¼˜åŒ–è¿­ä»£æ¬¡æ•°: {summary['total_iterations']}")
        
        improvements = summary.get('improvement_achieved', {})
        if improvements:
            print(f"\nğŸ“ˆ æ€§èƒ½æ”¹è¿›:")
            for metric, improvement in improvements.items():
                print(f"  {metric}: {improvement:+.1%}")
        
        targets_met = summary.get('targets_met', {})
        if targets_met:
            print(f"\nğŸ¯ ç›®æ ‡è¾¾æˆæƒ…å†µ:")
            for metric, met in targets_met.items():
                status = "âœ…" if met else "âŒ"
                print(f"  {status} {metric}")
        
        print(f"\nğŸ’¡ å»ºè®®:")
        for suggestion in report['recommendations']:
            print(f"  - {suggestion}")
        
        print(f"\nğŸ“‹ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {self.optimization_data_dir / 'final_optimization_report.json'}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨é—­ç¯åé¦ˆä¼˜åŒ–ç³»ç»Ÿ")
    print("ğŸ¯ å®ç°è‡ªåŠ¨æ§åˆ¶é—­ç¯ï¼šæµ‹è¯•â†’åˆ†æâ†’ä¼˜åŒ–â†’åé¦ˆâ†’å†æµ‹è¯•")
    print("â° å¼€å§‹æ—¶é—´:", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
    print()
    
    # åˆ›å»ºä¼˜åŒ–ç³»ç»Ÿ
    optimizer = é—­ç¯åé¦ˆä¼˜åŒ–ç³»ç»Ÿ()
    
    # å¯åŠ¨é—­ç¯ä¼˜åŒ–
    optimizer.å¯åŠ¨é—­ç¯ä¼˜åŒ–()
    
    print("\nğŸŠ é—­ç¯åé¦ˆä¼˜åŒ–ç³»ç»Ÿè¿è¡Œå®Œæˆ")

if __name__ == "__main__":
    main()
